* The serum Ig paper <2024-11-02 Sat>
** TODO Setting up the pipeline

Probably best to do this by copying code from the =igad_paper_pipeline=, the =conda= version.

- [X] delete redundant =smk= files
- [X] delete redundant =conda= environments
- [X] set up R package with code for meta-analysis etc.
- [-] use EBISPOT pipeline? Seems more defensible than rolling my own
  - [X] write out results to target directory; params.out_dir is not working
  - [X] fix problem of =work= directory which is not cleaned up in =harmonise_gwas= rule
  - [ ] cache EBISPOT/gwas-sumstats-harmoniser image once
  - [ ] determine list of columns which are 'minimal' for our purposes
  - [-] troubleshoot problematic sources
    - [-] check all headers for =rsid=-like column
    - [-] eldjarn
      - [-] format all
        - [-] problem with not reformatting =otherAllele= to =other_allele=
          - [ ] fix programmatically
          - [X] handle in ad hoc manner
            - [X] iga
            - [X] igg
            - [X] igm
        - [X] relabelling rsids to rsid (Hmmmm probably shouldn't, actually! Has ;-delimited values)
          - [X] should =gwas-ssf= handle this better?
          - [X] how are comma-separated rsIDs handled in this field? I.e. do we just drop everything with multiple rsIDs?
      - [X] igm
      - [X] igg
      - [X] iga
    - [X] EPIC
      - [X] format all
      - [X] igm
      - [X] igg
      - [X] iga
    - [X] pietzner
    - [X] scepanovic
    - [X] gudjonsson
    - [X] dennis
- [ ] suggestions for =gwas-ssf=
  - [ ] handle =otherAllele= to =other_allele=, see =eldjarn-iga=
    - maybe the issue is due to there being both =other_allele= and =otherAllele= in the raw file?
  - [ ] handle =chr= prefix in chrom column
    - [ ] run through validate step to see if this triggers anything
  - [ ] =rsids= handling
- [ ] submit PR for fix to concatenation issue
- [-] =sdY= standardisation is going to have to take place after harmonisation
  - [X] code to estimate sdY
  - [ ] copy over requisite 1kGP =merged.afreq= and =prune.in=
  - [ ] merge harmonised stats with LD-pruned set with MAF
  - [ ] write down the fact we used European 1kGP3 MAFs to estimate the sdY values for the sake of the Methods; this is an issue wrt. Icelandic samples

*** TODO Harmonised columns

- chromosome
- base_pair_location
- variant_id
- rsid
- effect_allele
- other_allele
- effect_allele_frequency (I believe this is usually absent, isn't calculated from reference)
- beta
- standard_error
- p_value

I believe there are =hm_=-prefixed columns, too.

*** Troubleshooting
**** TODO =pietzner-igg= stopping short <2024-11-18 Mon>

Is this because it doesn't need to be harmonised? Is the =meta.yml= configuring the run incorrectly?

Job stops after =ten_percent_counts=. The next step is =ten_percent_counts_sum=. This is invoked at line 51 in =major_direction.nf=.

Able to map most variants to build.

Maybe because the input file is not sorted? No, =liu-iga.tsv= was not sorted but I could process it. I had misnamed it as =pietzner-iga= in the =meta.yaml= file but I do not think that would change anything.

Running with =local= executor has it stop at =ten_percent_counts=.

Running with =executor= executor has it fail on =ten_percent_counts_sum=. See the relevant =.nextflow.log= next.

Running with =conda,singularity= (rather than =local,conda=) actually did allow it to progress, but then it failed for want of =pandas= in the environment.

Creating the =gwas_harm= environment; nextflow isn't available in this environment, though. Having to modify the version of PyYAML that they suggest.

Running with just the =conda= profile: stops at =ten_percent_counts=. Doing the same for 1-22 gets me to =concatenate_chr_splits=, at which point it fails on =chrMT=; this was when I ran the local checkout of the pipeline.

=pietzner-igg= is a big file; maybe run with more memory?

Now debugging by running my own fork of the pipeline.
#+begin_src
ten_to_sum=ten_percent_counts.out
                      .ten_sc
                      .groupTuple(by: 0)
                      .branch{pass:it[1].size()==nchr}
                      .map{it[0]}
#+end_src

The =branch= is the problem: I set the =chromlist= to =21,22=, checked that =nchr= was 2, and then got to the =branch= to find... tails off here. Was it 25?

We have chromosomes 1-23 in the file, I wonder if that is the issue. We still get =1 of 25= etc. in the =ten_percent_counts= step, stops after this, apparently =chromlist= makes no difference.

Running with =conda= and no =chromlist= gets it past the =ten_percent_counts_sum=.

What if I filtered it so we had only chromosomes 1-22?

Maybe I could fix that step later in the pipeline that doesn't allow concatenation of the empty file?

#+begin_quote
executor >  local (51)
[86/3c7586] NFC…ap_to_build (pietzner-igg) | 1 of 1 ✔
[32/205e9e] NFC…counts (pietzner-igg_chr7) | 25 of 25 ✔
[78/60c970] NFC…_counts_sum (pietzner-igg) | 1 of 1 ✔
[-        ] NFC…ion:generate_strand_counts -
[-        ] NFC…on:summarise_strand_counts -
[9b/c9ec06] NFC…zation (pietzner-igg_chr7) | 15 of 25
[-        ] NFC…arm:concatenate_chr_splits -
[-        ] NFC…LOGHARM:quality_control:qc -
[-        ] NFC…_control:harmonization_log -
[-        ] NFC…y_control:update_meta_yaml -
ERROR ~ Error executing process > 'NFCORE_GWASCATALOGHARM:GWASCATALOGHARM:main_harm:harmonization (pietzner-igg_chrMT)'

Caused by:
  Process `NFCORE_GWASCATALOGHARM:GWASCATALOGHARM:main_harm:harmonization (pietzner-igg_chrMT)` terminated with an error exit status (1)


Command executed:

  coordinate_system=$(grep coordinate_system pietzner-igg.tsv-meta.yaml | awk -F ":" '{print $2}' | tr -d "[:blank:]" )
  if test -z "$coordinate_system"; then coordinate="1-based"; else coordinate=$coordinate_system; fi
  
  header_args=$(utils.py -f MT.merged -harm_args);
  
  main_pysam.py     --sumstats MT.merged     --vcf /rds/project/rds-HNdhZnUvWRk/analysis/pid/common_variant_analysis/serum_ig_pipeline/resources/ebispot_harmoniser/reference/homo_sapiens-chrMT.vcf.gz     --hm_sumstats chrMT.merged_unsorted.hm     --hm_statfile chrMT.merged.log.tsv.gz     $header_args     --na_rep_in NA     --na_rep_out NA     --coordinate $coordinate     --palin_mode forward;
  
  chr=$(awk -v RS='     ' '/chromosome/{print NR; exit}' chrMT.merged_unsorted.hm)
  pos=$(awk -v RS='     ' '/base_pair_location/{print NR; exit}' chrMT.merged_unsorted.hm)
  
  head -n1 chrMT.merged_unsorted.hm > chrMT.merged.hm;
  tail -n+2 chrMT.merged_unsorted.hm | sort -n -k$chr -k$pos -T$PWD >> chrMT.merged.hm

Command exit status:
  1

Command output:
  (empty)

Command error:
  Traceback (most recent call last):
    File "/rds/project/rds-HNdhZnUvWRk/analysis/pid/common_variant_analysis/gwas-sumstats-harmoniser/bin/main_pysam.py", line 780, in <module>                                                
      main()
    File "/rds/project/rds-HNdhZnUvWRk/analysis/pid/common_variant_analysis/gwas-sumstats-harmoniser/bin/main_pysam.py", line 34, in main                                                     
      out_header = SumStatsTable(sumstats_file=args.sumstats)._set_header_order()
    File "/rds/project/rds-csoP2nj6Y6Y/tw395/mambaforge/envs/gwas_harm/lib/python3.9/site-packages/gwas_sumstats_tools/interfaces/data_table.py", line 188, in _set_header_order              
      header_order.extend([h for h in self.FIELDS_OPTIONAL if h in self.header()])
    File "/rds/project/rds-csoP2nj6Y6Y/tw395/mambaforge/envs/gwas_harm/lib/python3.9/site-packages/gwas_sumstats_tools/interfaces/data_table.py", line 188, in <listcomp>                     
      header_order.extend([h for h in self.FIELDS_OPTIONAL if h in self.header()])
    File "/rds/project/rds-csoP2nj6Y6Y/tw395/mambaforge/envs/gwas_harm/lib/python3.9/site-packages/gwas_sumstats_tools/interfaces/data_table.py", line 226, in header                         
      if self.is_table_content():
    File "/rds/project/rds-csoP2nj6Y6Y/tw395/mambaforge/envs/gwas_harm/lib/python3.9/site-packages/gwas_sumstats_tools/interfaces/data_table.py", line 105, in is_table_content               
      return etl.nrows(self.head_table(nrows=1)) > 0
    File "/rds/project/rds-csoP2nj6Y6Y/tw395/mambaforge/envs/gwas_harm/lib/python3.9/site-packages/petl/util/counting.py", line 22, in nrows                                                  
      return sum(1 for _ in data(table))
    File "/rds/project/rds-csoP2nj6Y6Y/tw395/mambaforge/envs/gwas_harm/lib/python3.9/site-packages/petl/util/counting.py", line 22, in <genexpr>                                              
      return sum(1 for _ in data(table))
    File "/rds/project/rds-csoP2nj6Y6Y/tw395/mambaforge/envs/gwas_harm/lib/python3.9/site-packages/petl/transform/basics.py", line 751, in iterrowslice                                       
      it = iter(source)
  TypeError: 'NoneType' object is not iterable

Work dir:
  /rds/project/rds-HNdhZnUvWRk/analysis/pid/common_variant_analysis/serum_ig_pipeline/results/gwas/gwas_ssf/work/df/4e35b098446f858482b55c44073655                                            

Tip: view the complete command output by changing to the process work dir and entering the command `cat .command.out`                                                                         

 -- Check '.nextflow.log' file for details

#+end_quote

Need to edit the above to run the =header_args= and =main_pysam.py= lines. Probably easier to get the paths etc. by writing the commands in a script.

It's definitely the =main_pysam.py= script that is causing problems:
#+begin_src
if args.hm_sumstats:
      out_handle = open_gzip(args.hm_sumstats, "wb")
      out_header = SumStatsTable(sumstats_file=args.sumstats)._set_header_order()
      tag_neg_log_10_p_value=False
      if "neg_log_10_p_value" in out_header:
          out_header.remove("neg_log_10_p_value")
          tag_neg_log_10_p_value=True
#+end_src

Problem is that there are no rows in =MT.merged=, the file to which =args.sumstats=.

***** Creating issue

Note:
- x of 25 when I'm only specifying 1-22
- stops after =ten_percent_counts=
- if they ask why I'm not restricting it to 1-22, say it's because I got further with the default setting and got an explicit error rather than an orderly exit after the =ten_percent_counts= stage

**** DONE Fixing =gwas_harm= environment

Looks like some of the pip dependencies conflict with those of the updated =gwas-sumstats-tools=

****** PR

- reference Vietnamese guy's PR, say doing the same but with the latest release of =gwas-sumstats-tools=
- updated =PyYAML=, =requests=, and specified a version for =numpy=, issue previously encountered https://github.com/EBISPOT/gwas-sumstats-tools/issues/45

***** Looking at this issue for =eldjarn-igg=

The =eldjarn-igg= data set progressed to writing out =ten_percent_total_strand_count.tsv=:
#+begin_quote
Palindromic variant     0
Forward strand variant  0
Reverse strand variant  0
No VCF record found     0
Invalid variant for harmonisation       0
palin_mode      drop
#+end_quote

This file is written out by =ten_percent_counts_sum.nf=. Looks like all the variants are in the =1_map_to_build/unmapped= file!

**** Test job also stopping short <2024-12-04 Wed>

Job stopping at =ten_percent_counts= as before.

This happened when I ran:
#+begin_src
nextflow -c /rds/project/rds-HNdhZnUvWRk/analysis/pid/common_variant_analysis/serum_ig_pipeline/config/harmoniser.config run /rds/project/rds-HNdhZnUvWRk/analysis/pid/common_variant_analysis/gwas-sumstats-harmoniser --ref /rds/project/rds-HNdhZnUvWRk/analysis/pid/common_variant_analysis/serum_ig_pipeline/resources/ebispot_harmoniser/reference -profile test,conda
#+end_src

Not sure why it does not work with =conda=: stopping after the =ten_percent_counts= step. Maybe because I'm rerunning it before deleting the previous output?

Trying to reproduce this with default settings (i.e. =test,singularity=) after dropping the =-c= argument but still running my local checkout of the harmoniser (65714615).
#+begin_src
nextflow run /rds/project/rds-HNdhZnUvWRk/analysis/pid/common_variant_analysis/gwas-sumstats-harmoniser --ref /rds/project/rds-HNdhZnUvWRk/analysis/pid/common_variant_analysis/serum_ig_pipeline/resources/ebispot_harmoniser/reference -profile test,singularity
#+end_src

#+begin_src
executor >  local (26)
[25/26245c] NFC…map_to_build (random_name) | 1 of 1 ✔
[a4/039746] NFC…_counts (random_name_chrX) | 25 of 25 ✔
[-        ] NFC…ion:ten_percent_counts_sum -
[-        ] NFC…ion:generate_strand_counts -
[-        ] NFC…on:summarise_strand_counts -
[-        ] NFC…RM:main_harm:harmonization -
[-        ] NFC…arm:concatenate_chr_splits -
[-        ] NFC…LOGHARM:quality_control:qc -
[-        ] NFC…_control:harmonization_log -
[-        ] NFC…y_control:update_meta_yaml -
Completed at: 04-Dec-2024 21:48:45
Duration    : 17m 47s
CPU hours   : 0.3
Succeeded   : 26
#+end_src

This still happens if I run it in a separate directory, =test=.

Running with the repo version (65726143):
#+begin_src
nextflow run EBISPOT/gwas-sumstats-harmoniser --ref /rds/project/rds-HNdhZnUvWRk/analysis/pid/common_variant_analysis/serum_ig_pipeline/resources/ebispot_harmoniser/reference -r $release_version -profile test,singularity
#+end_src

Hadn't set =release_version= (v1.1.10).

Had to delete the =.nextflow= directory to get this running; would this help with the other jobs?

Ok, =conda= version does not work even with this! Stops at =ten_percent_counts=.

I can run these on my own machine, might be due to the cluster.

***** Running the =test= locally

This works?
#+begin_src
  (base) tomw@toms-tpd:~/cam/serum_ig_pipeline$ sudo nextflow run EBISPOT/gwas-sumstats-harmoniser -r v1.1.10 -profile test,singularity
Nextflow 24.10.2 is available - Please consider updating your version to it

 N E X T F L O W   ~  version 24.10.0

Pulling EBISPOT/gwas-sumstats-harmoniser ...
 downloaded from https://github.com/EBISPOT/gwas-sumstats-harmoniser.git
Launching `https://github.com/EBISPOT/gwas-sumstats-harmoniser` [special_pike] DSL2 - revision: 436c17a91c [v1.1.10]

Start harmonising files
Harmonizing the file /root/.nextflow/assets/EBISPOT/gwas-sumstats-harmoniser/test_data/random_name.tsv
[-        ] process > NFCORE_GWASCATALOGHARM:GWASCATALOGHARM:major_direction:map_to_build            -
executor >  local (10)
[dd/b4e1e8] process > NFCORE_GWASCATALOGHARM:GWASCATALOGHARM:major_direction:map_to_build (random_name)             [100%] 1 of 1 ✔
[08/76cf43] process > NFCORE_GWASCATALOGHARM:GWASCATALOGHARM:major_direction:ten_percent_counts (random_name_chr1)  [100%] 2 of 2 ✔
[8c/2a1791] process > NFCORE_GWASCATALOGHARM:GWASCATALOGHARM:major_direction:ten_percent_counts_sum (random_name)   [100%] 1 of 1 ✔
[-        ] process > NFCORE_GWASCATALOGHARM:GWASCATALOGHARM:major_direction:generate_strand_counts                 -
[-        ] process > NFCORE_GWASCATALOGHARM:GWASCATALOGHARM:major_direction:summarise_strand_counts                -
[74/814d7d] process > NFCORE_GWASCATALOGHARM:GWASCATALOGHARM:main_harm:harmonization (random_name_chr22)            [100%] 2 of 2 ✔
[30/577ac7] process > NFCORE_GWASCATALOGHARM:GWASCATALOGHARM:main_harm:concatenate_chr_splits (random_name)         [100%] 1 of 1 ✔
[c1/8f7d1b] process > NFCORE_GWASCATALOGHARM:GWASCATALOGHARM:quality_control:qc (random_name)                       [100%] 1 of 1 ✔
[65/fdb023] process > NFCORE_GWASCATALOGHARM:GWASCATALOGHARM:quality_control:harmonization_log (random_name)        [100%] 1 of 1 ✔
[5d/7422ca] process > NFCORE_GWASCATALOGHARM:GWASCATALOGHARM:quality_control:update_meta_yaml (random_name)         [100%] 1 of 1 ✔
Completed at: 04-Dec-2024 18:03:32
Duration    : 1m 29s
CPU hours   : (a few seconds)
Succeeded   : 10
#+end_src

When I run my checkout, it finishes those missing jobs too when run with =singularity=.

**** Running =eldjarn-iga= <2024-12-05 Thu>

#+begin_src
[e1/8b66a5] NFC…nization_log (eldjarn-iga) | 1 of 1, failed: 1 ✘
[-        ] NFC…y_control:update_meta_yaml -
ERROR ~ Error executing process > 'NFCORE_GWASCATALOGHARM:GWASCATALOGHARM:quality_control:harmonization_log (eldjarn-iga)'

Caused by:
  Process `NFCORE_GWASCATALOGHARM:GWASCATALOGHARM:quality_control:harmonization_log (eldjarn-iga)` terminated with an error exit status (1)


Command executed:

  # Generating running log
  log_script.sh     -r "/rds/project/rds-HNdhZnUvWRk/analysis/pid/common_variant_analysis/serum_ig_pipeline/resources/ebispot_harmoniser/reference/homo_sapiens-chr15.vcf.gz"     -i eldjarn-ig
a.tsv     -c ten_percent_total_strand_count.tsv     -d report.txt     -h harmonised.tsv     -u unmapped     -o eldjarn-iga.running.log     -p v1.1.10
  
  N=$(awk -v RS='       ' '/hm_code/{print NR; exit}' harmonised.qc.tsv)
  sed 1d harmonised.qc.tsv| awk -F "    " '{print $'"$N"'}' | creat_log.py >> eldjarn-iga.running.log
  
  # extract harmonise result
  result=$(grep Result eldjarn-iga.running.log | cut -f2)
  
  # Prepare the gzip data
  chr=$(awk -v RS='     ' '/chromosome/{print NR; exit}' harmonised.qc.tsv)
  pos=$(awk -v RS='     ' '/base_pair_location/{print NR; exit}' harmonised.qc.tsv)
  
  cat harmonised.qc.tsv | bgzip -c > eldjarn-iga.h.tsv.gz
  tabix -c N -S 1 -f -s $chr -b $pos -e $pos eldjarn-iga.h.tsv.gz

Command exit status:
  1

Command output:
  /rds/project/rds-HNdhZnUvWRk/analysis/pid/common_variant_analysis/serum_ig_pipeline/resources/ebispot_harmoniser/reference/homo_sapiens-chr15.vcf.gz,eldjarn-iga.tsv,ten_percent_total_strand_count.tsv,report.txt,harmonised.tsv,unmapped,,,eldjarn-iga.running.log,v1.1.10

Command error:
  INFO:    Environment variable SINGULARITYENV_TMP is set, but APPTAINERENV_TMP is preferred
  INFO:    Environment variable SINGULARITYENV_TMPDIR is set, but APPTAINERENV_TMPDIR is preferred
  INFO:    Environment variable SINGULARITYENV_NXF_TASK_WORKDIR is set, but APPTAINERENV_NXF_TASK_WORKDIR is preferred
  /rds/project/rds-HNdhZnUvWRk/analysis/pid/common_variant_analysis/serum_ig_pipeline/resources/ebispot_harmoniser/reference/homo_sapiens-chr15.vcf.gz,eldjarn-iga.tsv,ten_percent_total_strand_count.tsv,report.txt,harmonised.tsv,unmapped,,,eldjarn-iga.running.log,v1.1.10
  awk: line 1: syntax error at or near }
  Traceback (most recent call last):
    File "/bin/creat_log.py", line 43, in <module>
      success_ratio=success_all/all
  ZeroDivisionError: division by zero
  

#+end_src

Looks like the issue is that the chromosome values are prefixed with =chr=.

Now running after fixing =chr= issue: 65782694.

Only 2,474,741 rows in the harmonised file, though. =10_percent_ratio= ('forward sites ratio') was 0.54, which meant palindromic variants were dropped. Only harmonised 7.81% of sites. 79.93% of input variants dropped as no match in the reference VCF, but far more were still mapped to hg38.

#+begin_src
  X	NA	G	A	0.0974	0.092386	NA	0.291759	chrX:156029849:G:A	.	A	0.53498	30695	0.00198	NA	NA
X	NA	C	C	-0.0513	0.123768	NA	0.678518	chrX:156029857:C:C	.	C	0.16844	30695	0.00094	NA	NA
X	NA	G	C	0.0513	0.123768	NA	0.678518	chrX:156029857:G:C	rs1384946096	C	0.16844	30695	0.00094	NA	NA
X	NA	C	CTTAGGG	-0.0061	0.063531	NA	0.923508	chrX:156029886:C:CTTAGGG	rs1440518544	CTTAGGG	0.03456	30695	0.00348	NA	NA
X	NA	T	T	0.0029	0.060766	NA	0.961936	chrX:156029888:T:T	.	T	0.01685	30695	0.00355	NA	NA
X	NA	*	T	-0.0029	0.059369	NA	0.961041	chrX:156029888:*:T	.	T	0.01726	30695	0.00355	NA	NA
X	NA	C	G	1.0176	0.434783	NA	0.019259	chrX:156029914:C:G	rs1301486121	G	1.71537	30695	0.00022	NA	NA
X	NA	C	G	-0.0193	0.05453	NA	0.723388	chrX:156029926:C:G	rs1378190828	G	0.14063	30694	0.0051	NA	NA
X	NA	A	G	-0.0351	0.056235	NA	0.532518	chrX:156029943:A:G	rs868390234	G	0.27367	30694	0.0049	NA	NA
X	NA	A	G	-0.0351	0.05618	NA	0.532119	chrX:156029949:A:G	rs867012337	G	0.27399	30694	0.0049	NA	NA
#+end_src

If I grep for the position of the last variant in the above subset of rows, I get a match for alleles, rsID, etc.

#+begin_src
  snakemake) [tw395@login-q-1 reference]$ zcat homo_sapiens-chrX.vcf.gz | grep "156029949"
X	156029949	rs1381077572	G	GG	.	.	dbSNP_151;TSA=insertion
X	156029949	rs867012337	A	C,G	.	.	dbSNP_151;TSA=SNV;E_Freq;E_TOPMed;E_gnomAD

#+end_src

Would it be any different if I relabelled the =rsids= column? Running this as 65787288. This works!

***** =other_allele= not relabelled properly <2024-12-05 Thu>

The =eldjarn-iga.json= file 'relabels' =otherAllele= as =otherAllele= rather than =other_allele=.

#+begin_quote
Chrom   Pos     Name    rsids   effectAllele    otherAllele     Beta    Pval    minus_log10_pval        SE      N       ImpMAF
#+end_quote

=effectAllele= is handled correctly.

****** PR for this issue

Would need to edit header schema. =otherAllele= is absent, but perhaps the matching checks for capitalised/uncapitalised versions.

***** =rsid= column where multiple rsIDs are present <2024-12-06 Fri>

There are 1,252,336 rows in the file with the comma-delimited rsIDs (33,449,991 rows in total).

=unmapped= has 445,802 rows, 49,740 instances of commas (more than one in some fields).

I lose just over 20% sites in total from 33.5M variants. Hmmm...

#+begin_quote
6. Failed harmonisation

21.63% ( 7139118 of 33004201 ) sites failed to harmonise.

hm_code Number  Percentage      Explanation
15      3370190 10.21%  No matching variants in reference VCF; Cannot harmonise
14      3767139 11.41%  Required fields are not known; Cannot harmonise
16      1789    0.01%   Multiple matching variants in reference VCF (ambiguous); Cannot harmonise

#+end_quote

Are we losing those code 15's for a good reason? Looking at the files in =4_harmonization=, looks like a lot of those I am losing are indels, SNPs missing information.

Does the coordinate-based step in =map_to_build.py= save any rows with multiple rsIDs? There should be some in the =eldjarn-iga= output file:
#+begin_quote
> dat[, .N, by = hm_coordinate_conversion]
   hm_coordinate_conversion        N
                     <char>    <int>
1:                       lo   118768
2:                       rs 25746315
> dat[rsid %like% ',']
Empty data.table (0 rows and 17 cols): chromosome,base_pair_location,effect_allele,other_allele,beta,standard_error...
#+end_quote

Maybe the rsID is updated? Apparently so, I get 6,717 rows, e.g.
#+begin_quote
> merged[!is.na(rsid.y)][, .(chromosome, base_pair_location, rsid.x, rsid.y)]
      chromosome base_pair_location       rsid.x
          <char>              <int>       <char>
   1:          1          112568861  rs377429784
   2:          1          151781328  rs550995792
   3:          1          166716818  rs143243322
   4:         10           91154560  rs780262309
   5:         11             197169    rs5789177
  ---                                           
6713:          9           39093202  rs375232468
6714:          9           39152534 rs1198576337
6715:          9           39209599  rs372042997
6716:          9           39465460 rs1437888070
6717:          9          102285530   rs78170949
                                   rsid.y
                                   <char>
   1:             rs377429784,rs869255253
   2: rs1491351417,rs550995792,rs60652277
   3:              rs143243322,rs60040574
   4:             rs750427664,rs780262309
   5:                 rs3839961,rs5789177
  ---                                    
6713:              rs375232468,rs60208177
6714:              rs1198576337,rs4062758
6715:              rs372042997,rs60690302
6716:             rs1437888070,rs77517622
6717:              rs398096568,rs78170949
#+end_quote

Well, good job, EBI, this was a problem I did not need to fix, I think.

**** TODO Is =rsid=-like column present elsewhere? <2024-12-06 Fri>

#+begin_src
  dennis-iga.tsv
chromosome	variant_id	base_pair_location	A1	A2	N	AF1	BETA	SE	p_value
dennis-igg.tsv
chromosome	variant_id	base_pair_location	A1	A2	N	AF1	BETA	SE	p_value
eldjarn-iga.tsv
Chrom	Pos	Name	rsids	effectAllele	otherAllele	Beta	Pval	minus_log10_pval	SE	N	ImpMAF
eldjarn-igg.tsv
Chrom	Pos	Name	rsids	effectAllele	otherAllele	Beta	Pval	minus_log10_pval	SE	N	ImpMAF
eldjarn-igm.tsv
Chrom	Pos	Name	rsids	effectAllele	otherAllele	Beta	Pval	minus_log10_pval	SE	N	ImpMAF
gudjonsson-iga.tsv
variant_id	p_value	chromosome	base_pair_location	effect_allele	other_allele	effect_allele_frequency	beta	standard_error	odds_ratio	ci_lower	ci_upper
gudjonsson-igg.tsv
variant_id	p_value	chromosome	base_pair_location	effect_allele	other_allele	effect_allele_frequency	beta	standard_error	odds_ratio	ci_lower	ci_upper
gudjonsson-igm.tsv
variant_id	p_value	chromosome	base_pair_location	effect_allele	other_allele	effect_allele_frequency	beta	standard_error	odds_ratio	ci_lower	ci_upper
iga.tsv
chr	rsid	pos	REF	ALT	all_AA	all_AB	all_BB	maf	hwe	p_value	beta	se	info_impute	impute	N
igg.tsv
chr	rsid	pos	REF	ALT	all_AA	all_AB	all_BB	maf	hwe	p_value	beta	se	info_impute	impute	N
igm.tsv
chr	rsid	pos	REF	ALT	all_AA	all_AB	all_BB	maf	hwe	p_value	beta	se	info_impute	impute	N
liu-decode-iga.tsv
SNP	CHR	BP_hg19	A1	A2	BETA	SE	P
liu-iga.tsv
SNP	CHR	BP_hg19	A1	A2	BETA	SE	P
pietzner-iga.tsv
rsid	MarkerName	Allele1	Allele2	Freq1	FreqSE	MinFreq	MaxFreq	Effect	StdErr	Pvalue	Direction	HetISq	HetChiSq	HetDf	HetPVal	TotalSampleSize	chr	pos
pietzner-igg.tsv
rsid	MarkerName	Allele1	Allele2	Freq1	FreqSE	MinFreq	MaxFreq	Effect	StdErr	Pvalue	Direction	HetISq	HetChiSq	HetDf	HetPVal	TotalSampleSize	chr	pos
pietzner-igm.tsv
rsid	MarkerName	Allele1	Allele2	Freq1	FreqSE	MinFreq	MaxFreq	Effect	StdErr	Pvalue	Direction	HetISq	HetChiSq	HetDf	HetPVal	TotalSampleSize	chr	pos
scepanovic-iga.tsv
chromosome	base_pair_location	variant_id	other_allele	effect_allele	effect_allele_frequency	test	obs_ct	beta	standard_error	t_stat	p_value	ci_upper	odds_ratio	ci_lower
scepanovic-igg.tsv
chromosome	base_pair_location	variant_id	other_allele	effect_allele	effect_allele_frequency	test	obs_ct	beta	standard_error	t_stat	p_value	ci_upper	ci_lower	odds_ratio
scepanovic-igm.tsv
chromosome	base_pair_location	variant_id	other_allele	effect_allele	effect_allele_frequency	test	obs_ct	beta	standard_error	t_stat	p_value	odds_ratio	ci_lower	ci_upper

#+end_src

Ensuring that we've handled these columns correctly where necessary:
- [-] eldjarn
  - [ ] missing rows where we have multiple rsIDs; how come we don't just use coordinates there? Apparently =map_to_build= does do this.
- [ ] EPIC
- [ ] pietzner

**** TODO Using config to specify column labels <2024-12-23 Mon>

#+begin_quote
gwas/plot_gwas_manhattan.R:chr_col <- snakemake@params[['chr_col']]
gwas/plot_gwas_manhattan.R:bp_col <- snakemake@params[['bp_col']]
gwas/plot_gwas_manhattan.R:p_col <- snakemake@params[['p_col']]
gwas/plot_gwas_manhattan.R:snp_col <- snakemake@params[['snp_col']]
gwas/lead_snp_annotation.py:chr_col = snakemake.params.chr_col
gwas/lead_snp_annotation.py:bp_col = snakemake.params.bp_col
gwas/lead_snp_annotation.py:snp_col = snakemake.params.snp_col
gwas/lead_snp_annotation.py:ref_col = snakemake.params.ref_col
gwas/lead_snp_annotation.py:alt_col = snakemake.params.alt_col
gwas/join_pair_gwas_stats.R:chr_col <- snakemake@params[['chr_col']]
gwas/join_pair_gwas_stats.R:bp_col <- snakemake@params[['bp_col']]
gwas/join_pair_gwas_stats.R:ref_col <- snakemake@params[['ref_col']]
gwas/join_pair_gwas_stats.R:alt_col <- snakemake@params[['alt_col']]
gwas/join_pair_gwas_stats.R:p_col <- snakemake@params[['p_col']]
gwas/join_pair_gwas_stats.R:beta_col <- snakemake@params[['beta_col']]
gwas/join_pair_gwas_stats.R:se_col <- snakemake@params[['se_col']]
gwas/join_pair_gwas_stats.R:id_col <- snakemake@params[['id_col']]
gwas/make_plink_range.R:chr_col <- snakemake@params[['chr_col']]
gwas/make_plink_range.R:bp_col <- snakemake@params[['bp_col']]
gwas/make_plink_range.R:ref_col <- snakemake@params[['ref_col']]
gwas/make_plink_range.R:alt_col <- snakemake@params[['alt_col']]
gwas/distance_clump.R:chr_col <- snakemake@params[['chr_col']]
gwas/distance_clump.R:bp_col <- snakemake@params[['bp_col']]
gwas/distance_clump.R:ref_col <- snakemake@params[['ref_col']]
gwas/distance_clump.R:alt_col <- snakemake@params[['alt_col']]
gwas/distance_clump.R:snp_col <- snakemake@params[['snp_col']]
gwas/distance_clump.R:p_col <- snakemake@params[['p_col']]
gwas/distance_clump.R:beta_col <- snakemake@params[['beta_col']]
gwas/distance_clump.R:se_col <- snakemake@params[['se_col']]
ldsc_and_sumher/preprocess_sumstats.R:chr_col <- snakemake@params[['chr_col']]
ldsc_and_sumher/preprocess_sumstats.R:bp_col <- snakemake@params[['bp_col']]
ldsc_and_sumher/preprocess_sumstats.R:ref_col <- snakemake@params[['ref_col']]
ldsc_and_sumher/preprocess_sumstats.R:alt_col <- snakemake@params[['alt_col']]
ldsc_and_sumher/preprocess_sumstats.R:p_col <- snakemake@params[['p_col']]
ldsc_and_sumher/preprocess_sumstats.R:beta_col <- snakemake@params[['beta_col']]
ldsc_and_sumher/preprocess_sumstats.R:snp_col <- snakemake@params[['snp_col']]
ldsc_and_sumher/process_sum_stats_for_merged_gwas.R:chr_col <- snakemake@params[['chr_col']]
ldsc_and_sumher/process_sum_stats_for_merged_gwas.R:bp_col <- snakemake@params[['bp_col']]
ldsc_and_sumher/process_sum_stats_for_merged_gwas.R:ref_col <- snakemake@params[['ref_col']]
ldsc_and_sumher/process_sum_stats_for_merged_gwas.R:alt_col <- snakemake@params[['alt_col']]
ldsc_and_sumher/process_sum_stats_for_merged_gwas.R:beta_a_col <- snakemake@params[['beta_a_col']]
ldsc_and_sumher/process_sum_stats_for_merged_gwas.R:beta_b_col <- snakemake@params[['beta_b_col']]
ldsc_and_sumher/process_sum_stats_for_merged_gwas.R:se_a_col <- snakemake@params[['se_a_col']]ldsc_and_sumher/process_sum_stats_for_merged_gwas.R:se_b_col <- snakemake@params[['se_b_col']]
#+end_quote

Need to replace the likes of =snakemake@params[['chr_col']]= with =snakemake@config$chr_col=

*** Notes on harmoniser pipeline
**** Process

***** =map_to_build=

Updates variant's position by mapping rsID to Ensembl reference. If not possible, liftover is used.

Variants which cannot be mapped are put in =1_map_to_build/unmapped=.

***** =ten_sc=

This infers strand orientation by using a 'strand consensus approach' in order to deal with palindromic variants. It looks at 10% of non-palindromic variants, selected at random, comparing them to the Ensembl VCF reference.

***** What is relevant to the handling of rsID synonyms? <2024-12-20 Fri>

****** =make_synonym_table.py=

This script is invoked in =make_local_synonyms_table=, used to create =rsID.sql=. Can we use the information in that?

=basic_qc_nf.py= takes the =rsID.sql= file as its 'synonyms' database.

#+begin_src
sqlite> .schema
CREATE TABLE variation_synonym (
    variation_id int(10)  NOT NULL,
    name varchar(255) DEFAULT NULL
    );
CREATE INDEX rsid_idx on variation_synonym (name);
CREATE INDEX syn_idx on variation_synonym (variation_id);
sqlite> PRAGMA table_info(variation_synonym)
   ...> 
   ...> ;
0|variation_id|int(10)|1||0
1|name|varchar(255)|0|NULL|0
#+end_src

It looks like this doesn't store alternatives, the following did not return any rows:

#+begin_src
sqlite> select * from variation_synonym where name like '%,%' limit 1;
#+end_src

****** =vcf= file

This stores rsIDs and some are duplicated for a given position.

****** Selecting the best rsIDs from duplicates

*** How do I have the harmoniser running on CSD3 as of <2024-12-22 Sun>?

I run =gwas-ssf= then the likes of:
#+begin_src
cd /rds/project/rds-HNdhZnUvWRk/analysis/pid/common_variant_analysis/serum_ig_pipeline/results/gwas/gwas_ssf/eldjarn-iga

conda activate gwas_harm

nextflow -c /rds/project/rds-HNdhZnUvWRk/analysis/pid/common_variant_analysis/serum_ig_pipeline/config/harmoniser.config run /rds/project/rds-HNdhZnUvWRk/analysis/pid/common_variant_analysis/gwas-sumstats-harmoniser --ref /rds/project/rds-HNdhZnUvWRk/analysis/pid/common_variant_analysis/serum_ig_pipeline/resources/ebispot_harmoniser/reference --harm --file /rds/project/rds-HNdhZnUvWRk/analysis/pid/common_variant_analysis/serum_ig_pipeline/results/gwas/gwas_ssf/eldjarn-iga/eldjarn-iga.tsv -profile singularity
#+end_src

NB:

1. my =harmoniser.config=
2. my fork of the =gwas-sumstats-harmoniser=
3. =singularity= profile

Re: 2, if my fix to the strand counts step was merged in through a PR, I could probably revert to using the public version.

** TODO estimating sdY in all data sets

** Study inclusion

*** Scepanovic and sdY estimates <2025-01-10 Fri>

There are only 1,000 subjects in this study, so inclusion is hardly critical to the power of the meta-analysis.

[[https://genomemedicine.biomedcentral.com/articles/10.1186/s13073-018-0568-8#Sec2][From the paper]]:

#+begin_quote
For single-variant association analyses, we only considered SNPs with a MAF of > 5% (N = 5,699,237). We used PLINK (v1.9) [24] to perform logistic regression for binary phenotypes (serostatus: antibody positive versus negative) and linear regression for continuous traits (log10-transformed quantitative measurements of antibody levels in seropositive donors). The first two principal components of a PCA based on genetic data, age and sex, were used as covariates in all tests. In order to correct for baseline difference in IgG production in individuals, total IgG levels were included as covariates when examining associations with antigen-specific antibody levels, total IgM, IgE, and IgA levels. From a total of 53 additional variables additional co-variates, selected by using elastic net [25] and stability selection [26] as detailed elsewhere [16], were included in some analyses (Additional file 1: Table S3). For all genome-wide association studies, we used a genome-wide significant threshold (Pthreshold < 2.6 × 10−9) corrected for the number of antigens and immunoglobulin classes tested (N = 19). For specific HLA analyses, we used PLINK (v1.07) [27] to perform conditional haplotype-based association tests and multivariate omnibus tests at multi-allelic amino acid positions.
#+end_quote

I would need an estimate of the standard deviation of Y to restandardise the summary statistics. I think it's not worth it.

They do give this number, however:

#+begin_quote
To characterize the variability in humoral immune responses between healthy individuals, we measured total IgG, IgM, IgA, and IgE levels in the plasma of the 1000 donors of the Milieu Interieur (MI) cohort. After log10 transformation, total IgG, IgM, IgA, and IgE levels showed normal distributions, with a median ± sd of 1.02 ± 0.08 g/l, 0.01 ± 0.2 g/l, 0.31 ± 0.18 g/l, and 1.51 ± 0.62 UI/ml, respectively
#+end_quote

Note that these are on the log10 scale, too. The sdY.est procedure recovered the SD values pretty well:

| Isotype | Median |   SD | Median sdY.est |
|---------+--------+------+----------------|
| IgG     |   1.02 | 0.08 |          0.079 |
| IgM     |   0.01 |  0.2 |          0.193 |
| IgA     |   0.31 | 0.18 |          0.171 |

*** What about the scale of the other summary statistics? <2025-01-10 Fri>

sdY estimates:

#+begin_quote
           dataset median(sdY.est)
 1:        liu-iga 1.1675795
 2: liu-decode-iga 1.5899747
 3:     dennis-iga 0.9110791
 4:     dennis-igg 0.9345117
 5:       epic-iga 0.4996091
 6:       epic-igg 0.2871838
 7:       epic-igm 0.5358721
 8: scepanovic-igg 0.0788076
 9: scepanovic-igm 0.1933939
10: scepanovic-iga 0.1712270
11:   pietzner-igm 0.9821195
12:   pietzner-iga 1.0155681
13:   pietzner-igg 1.0145151
14: gudjonsson-igg 0.9441563
15: gudjonsson-iga 0.9342935
16: gudjonsson-igm 0.9793915
17:    eldjarn-igg 1.0449364
18:    eldjarn-iga 1.1091828
19:    eldjarn-igm 1.0969310
#+end_quote

| Study      | Scale           | Notes                                                                 |
|------------+-----------------+-----------------------------------------------------------------------|
| Dennis     | standard normal | rank-based INT, sdY.est values suggestive of standardised Y           |
| Liu        | standard normal | standard-normalised residuals from regression of log Y on age and sex |
| EPIC       | log             |                                                                       |
| Pietzner   | standard normal | rank-based INT                                                        |
| Gudjonsson | Box-Cox         | Box-Cox transformation                                                |
| Eldjarn    | standard normal | rank-based INT                                                        |
| Scepanovic | log10           |                                                                       |

NB: 'INT' is inverse normal transformation, so on the scale of a standard normal. See Fig1b in the Dennis paper for where I saw this.

I suppose these are all ways of getting response variable values to be approximately ~ N(0,1). log10 and log scales differ by log(10), so standardising the betas and SEs should take care of this.

**** Dennis

#+begin_quote
In our primary analysis, we transformed lab values to fit the normal distribution to improve the performance of the linear regression models [21]. We applied the rank-based inverse normal quantile transformation to all labs, which ensured trait normality by replacing the value of each observation with its quantile from the standard normal distribution. The inverse normal quantile transformation thus preserved the rank ordering of observations, but not the values themselves, and model coefficients therefore are uninterpretable on the original scale.
#+end_quote

**** Liu

#+begin_quote
Multi-ancestry cohorts were classified into ancestry-specific strata based on global principal component analysis. In each sub-cohort, serum IgA levels were log-transformed and expressed as standard-normalized residuals from regression of log-transformed IgA levels against age and sex. We performed genome-wide association testing in each cohort for the markers that were imputed at high quality (
) using a linear regression model under additive coding of the dosage genotypes, and with adjustment for cohort-specific significant principal components (PCs) of ancestry78. To quantify potential inflation of type I error due to stratification or technical artifacts, we estimated the genomic inflation factor for each cohort but detected no substantial inflation with lambda <1.05 in each individual study. We performed a fixed-effects as well as TransMeta random effects meta-analysis to combine the results of all 17 individual cohort summary statistics using METAL79 and TransMeta21 software, respectively. All significant loci were further assessed for heterogeneity by derivation of Heterogeneity Index (I2) and by testing using Cochrane’s heterogeneity test in PLINK80. The quantile-quantile plot of the final meta-analysis showed no global departures from the expected null distribution, with the genomic inflation factor estimated at 1.016 (Supplementary Fig. 2). The genome-wide significant signals were defined by the generally accepted P < 5.0 × 10−8 and signals with P < 1.0 × 10−6 were considered as suggestive.
#+end_quote

**** EPIC

Hmmm, 'log-transformed' and then 'standardised'?

#+begin_quote
Prior to running the GWAS, samples were removed if they had: age greater than 80 years at the time of sampling; absence of genetic data; non-European ancestry; presence of relatives in the EPIC Norfolk sample as indicated by π >= 0.1875. Variants with imputation quality (info) < 0.4, Hardy-Weinberg Equilibrium p-value < 1x10-6, minor allele frequency (MAF) < 0.001, or effect size/standard error > 10 were removed. The log-transformed IgA phenotypes were standardised and the GWAS was performed using an additive model in SNPTEST (v2.5.4-beta3) incorporating age, sex, and scores on the first ten principal components of the genetic relatedness matrix.
#+end_quote

#+begin_quote
> dat[, lapply(.SD, median, na.rm = T), .SDcols = names(dat) %like% 'IG']
   IGA_CONC IGG1_CONC IGG2_CONC IGG3_CONC IGG4_CONC IGM_CONC IGG_CONC
      <num>     <num>     <num>     <num>     <num>    <num>    <num>
1: 233.9935   582.268   227.672     43.63    34.035   65.836   932.63
#+end_quote

NB: I created the =IGG_CONC= column as the sum of the IgG subclasses.

What was the sdY in the raw data? I don't know the subset of samples used for the GWAS of each isotype, I have 9,610 data points here. What is the sd of Y on different scales?

#+begin_quote
> dcast(melt(rbound, id.vars = 'scale'), variable ~ scale)[, .(variable, raw, log, log10)]
Key: <variable>
    variable       raw       log     log10
      <fctr>     <num>     <num>     <num>
1:  IGA_CONC 134.52692 0.5037606 0.2187805
2: IGG1_CONC 226.56262 0.3543768 0.1539039
3: IGG2_CONC 117.06080 0.5133363 0.2229391
4: IGG3_CONC  37.24913 0.5951565 0.2584732
5: IGG4_CONC  66.30797 1.0375210 0.4505896
6:  IGM_CONC  52.42656 0.5423559 0.2355422
7:  IGG_CONC 274.35088 0.2836292 0.1231786
#+end_quote

For what it's worth, log10 was used in that other paper. Comparing with the =sdY.est= values:

#+begin_quote
           dataset median(sdY.est)
 5:       epic-iga 0.4996091
 6:       epic-igg 0.2871838
 7:       epic-igm 0.5358721
#+end_quote

Looks like there's a very good match between the log scale values and the estimates we recover here. What about normality? Can't paste a plot in here but it looks ok. I think the location's not an issue as we have the intercept in the regression, so really it's just scale that's the issue.

**** Pietzner

#+begin_quote
Genome-wide association studies for each protein target (rank-based inverse normal-transformed aptamer abundance corrected for age, sex, the first ten genetic principal components and test site) were run for each array separately using the BGENIE software (v1.3) (74) and the results were combined in a fixed-effects meta-analysis in METAL (75). We restricted the GWAS to variants with a minor allele frequency threshold of at least 1%.
#+end_quote

More detail from their Covid paper:

#+begin_quote
After excluding ancestry outliers and related individuals, 10,708 Fenland participants had both phenotypes and genetic data for the GWAS (OMICS = 8350, Core-Exome=1026, and GWAS = 1332). Within each genotyping subset, aptamer abundances were transformed to follow a normal distribution using the rank-based inverse normal transformation. Transformed aptamer abundances were then adjusted for age, sex, sample collection site, and 10 principal components in STATA v14, and the residuals used as input for the genetic association analyses. Test site was omitted for protein abundances measured by Olink as those were all selected from the same test site. Genome-wide association was performed under an additive model using BGENIE (v1.3)45. Results for the three genotyping arrays were combined in a fixed-effects meta-analysis in METAL48. Following the meta-analysis, 17,652,797 genetic variants, also present in the largest subset of the Fenland data (Fenland-OMICS), were taken forward for further analysis.
#+end_quote

**** Gudjonsson

#+begin_quote
Data processing and statistical analysis were performed using R (v3.5.1 & 4.0.1) and Rstudio (v1.1.456), unless otherwise specified. Box-Cox transformation was applied on the protein data55 and extreme outlier values were excluded, defined as values above the 99.5th percentile of the distribution of 99th percentile cutoffs across all proteins after scaling, resulting in the removal of an average 11 samples per SOMAmer, as previously described18. Within the AGES cohort, 5368 individuals had both genetic data and protein measurements. With that sample set, 7,506,463 variants were tested for association with each of the 4782 SOMAmers separately, in a linear regression model with age, sex, 5 genetic principal components, and genotyping platform as covariates using PLINK 2.0. To obtain independent genetic signals, we performed a stepwise conditional association analysis for each SOMAmer separately with the GCTA-COJO software19,20. We conditioned on the current lead variant, defined as the variant with the lowest P-value, and then kept track of any new lead variants with study-wide-significant associations. Variants in strong LD (r2 > 0.9) with previously chosen lead variants were not considered for joint analysis to avoid multicollinearity. The independent signals defined by GCTA-COJO were subsequently subjected to a validation analysis where the joint models were tested using individual-level data in AGES and those remaining study-wide significant retained. Associations with independent lead variants within 300 kb window of the gene boundaries of the protein-coding gene were defined as cis-signals, and otherwise in trans. To compare independent signals between SOMAmers, we define any signals with lead variants in strong LD (r2 > 0.9) as the same signal. Due to the complex LD structure and high pleiotropy of the MHC region56 (chr.6, 28.47–34.45 Mb) we collapsed all signals within that region to a single signal. To define loci harboring independent signals, we defined a 300 kb window around each independent signal (150 kb up- and downstream of lead variants) and collapsed all such intersecting windows. Therefore, the definition of loci is solely based on physical distances while the definition of independent signals is solely based on LD structure. Variants were annotated using the Ensembl Variant Effect Predictor57 (v104, “per_gene” option), where PAVs affecting the corresponding protein target were defined as those with the following consequences: splice acceptor variant, splice donor variant, splice region variant, stop gained, stop lost, start lost, frameshift variant, missense variant or frameshift variant. The GWAS results were visualized using Circos58. Pathway enrichment was performed using gProfiler59, using the full set of measured proteins as background and considering Benjamini–Hochberg FDR < 0.05 as statistically significant. Enrichment of tissue-elevated gene expression was performed using data from the Human Protein Atlas24 with a Fisher’s exact test, considering Benjamini–Hochberg FDR < 0.05 as statistically significant.
#+end_quote

**** Eldjarn

#+begin_quote
Genome-wide association study

We rank-inverse normal transformed the measurements for each assay and adjusted them for age, sex and sample age. We standardized the residuals using rank-inverse normal transformation and used the standardized values as phenotypes for genome-wide association testing using a linear mixed model (BOLT-LMM71). We used LD score regression to account for inflation in test statistics due to cryptic relatedness and stratification72.

We computed P values using a likelihood ratio test and adjusted for multiple testing by using the same significance threshold (1.8 × 10−9) as in our previous study on the Icelandic dataset2.

We defined a pQTL association to be cis if the pQTL was located within 1 Mb of the transcription start site for the gene that encodes the target protein, as reported by UniProt, and trans otherwise.

Of the 2,941 assays on the Olink Explore 3072 platform, data from UKB for 2,931 assays were used for GWAS analysis.

The number of variants we test in Iceland (33.5 million) is about 40% lower than in UKB (57.7 million). The difference is largely due to very rare variants. However, the difference between them would result in a multiple testing correction threshold in UKB of 8.7 × 10−10 instead of 1.8 × 10−9. A total of 153 (1%) of the cis pQTLs are between those two thresholds and 1,608 (5%) of the trans pQTLs.

For replication between platforms, the P value threshold is 0.05, with the requirement that initial and replication associations are in the same direction.




#+end_quote

**** Scepanovic

#+begin_quote
For single-variant association analyses, we only considered SNPs with a MAF of > 5% (N = 5,699,237). We used PLINK (v1.9) [24] to perform logistic regression for binary phenotypes (serostatus: antibody positive versus negative) and linear regression for continuous traits (log10-transformed quantitative measurements of antibody levels in seropositive donors). The first two principal components of a PCA based on genetic data, age and sex, were used as covariates in all tests. In order to correct for baseline difference in IgG production in individuals, total IgG levels were included as covariates when examining associations with antigen-specific antibody levels, total IgM, IgE, and IgA levels. From a total of 53 additional variables additional co-variates, selected by using elastic net [25] and stability selection [26] as detailed elsewhere [16], were included in some analyses (Additional file 1: Table S3). For all genome-wide association studies, we used a genome-wide significant threshold (Pthreshold < 2.6 × 10−9) corrected for the number of antigens and immunoglobulin classes tested (N = 19). For specific HLA analyses, we used PLINK (v1.07) [27] to perform conditional haplotype-based association tests and multivariate omnibus tests at multi-allelic amino acid positions.
#+end_quote

*** Which data sets should I rescale? <2025-01-11 Sat>

All three =pietnzer= data sets, =gudjonsson-iga=, =eldjarn-igg= are within 0.05 of 1 (the expected sdY under N(0,1)), so I'll leave these as they are for fear of introducing more noise into them.

** TODO Z-score plots

** Existing associations

I've tabulated these in the past, but now we have two studies, Gudjonsson and Eldjarn, whose associations don't seem to be tabulated in the usual places.

** Content for the paper

*** Introduction

Idea that the study of common-variant architecture of physiological trait might inform understanding of traits in which dysregulation of the same antibody isotypes is implicated. Could cite our IgAD paper here but that seems a bit obnoxious; Kiryluk/Liu paper talked about IgAN.

*** Methods

Re: sdY estimation, I used a prune of the 1kGP panel of SNPs with MAF > 0.005 in Europeans rather than a panel of SNPs specific to each data set.
