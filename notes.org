* The serum Ig paper <2024-11-02 Sat>
** TODO list

- [ ] rerun MR downstream of new lead SNP datasets
  - [ ] IgA
  - [ ] IgM
  - [ ] IgA
- [ ] need some sort of consensus MAF rule based on best available estimate
- [ ] redo beta vs maf plot once we have all EAF
- [-] Z-score plots
  - [X] draw them
  - [ ] inspect them
- [-] coloc
  - [ ] talk to Chris about approach, need to make clear I'm not using all of her code and why
  - [ ] inspect plots
  - [ ] 17q11-21 locuszoomr plot
  - [X] Ig
- [ ] MR needs some consideration:
  - [ ] heterogeneity and use of penalty

*** TODOs to integrate

****** Serum Ig paper

******* =serum_ig_pipeline=

- [ ] report =liu-iga= and =liu-decode-iga= (inclusion of 4,699 SNPs with p < 1e-6) sdY.est disparity

******** Ideas

- [ ] comparison with 23andme infection summary statistics
- [ ] do loci influencing volume of ab production also affect antibody repertoires?
- [ ] local rg estimation with SUPERGNOVA?

******** Writing

********* Introduction

********** h2 estimate studies:

- 'The genetic control of antibody production. A study of isoimmune antibodies in cattle twins'

********** Additional general Ig studies

Seems like I have too many citations as it is!

*********** IgE

- Weidinger et al. (2008)
- Granada et al. (2013)
- Levin et al. (2013)
- Liao et al. (2013)
- Akenroye et al. (2022)
- Daya et al. (2022)

********** General references:

-  Gonzalez-Quintela for sex-specific variation

********** Things to mention

- [ ] meta-analysis of (Western?) European and Icelandic populations

********* Material and methods

- [X] describe standardisation procedure
- [X] reference IgAD paper for EPIC GWAS in Material and Methods
- [X] was Pietzner SMP'd?
- [X] need to add GRAMD1B as known association for IgM via anti-PC IgM study in CLL (mentioned in the IgE publications, too, not sure if GWS), also Ig light chain amyloidosis
- [ ] mention SMP issue
- [X] exclusion of IGH
- [ ] cite new locuszoomr paper

********* Discussion

- [ ] viktorin Swedish twin study has h2 estimates for serum IgA, ~0.5

******** Analyses

- [ ] need reminder that we need to drop low info score EPIC SNPs
- [-] fetch MAF for unknown SNPs
  - [X] query gnomAD
  - [X] plot effect size vs. maf
  - [ ] refactor use of gnomad MAFs, stop fetching them in the =annotate_lead_snps= rules
  - [ ] need to replace EAF where NA or 0 (for rarer SNPs)
- [ ] add IGH explanation
- [ ] better Manhattan plots
  - [ ] drop gene names; if want to restore, need a better way
- [ ] compile rsids for meta-analyses
  - [ ] add to annotated lead SNPs where it is missing
- [ ] need to replace =global.yaml= with an R-specific one
- [ ] exclusion of IGH when? Post meta-analysis? Definitely needs to be excluded from downstream analyses
  - [ ] need an analysis of the Manhattan plots, locuszoomr at the IGH locus (IGK and IGL worth a look, too); code for this is in =pid_cfdr_pipeline=
- [ ] Ig rg estimation
  - [ ] run job
- [ ] local rg with SUPERGNOVA

********* Rules to crib from =pid_cfdr_pipeline=

- [ ] Ig* lead SNP tables in =cvid_paper/tables.smk=
- [ ] =pub/cvid_paper/ig_locuszoom_plots.smk=
- [ ] =pub/cvid_paper/zscore_plots.smk=

******** Outstanding harmoniser issues

- [ ] need to ultimately reintegrate stuff on the =ebispot_harmoniser= branch back into the =master= branch
- [X] =otherAllele= formatting is done by hand, is an issue with the Eldjarn data sets
  - [X] investigate hypothesis that problem is that =other_allele= and =otherAllele= are both present in input to =gwas-ssf=
  - [X] =gwas-ssf= worked the second time
  - [X] not working again <2025-01-24 Fri>, problem with config output I think rather than the format step
- [ ] needs to strip leading =chr= from chrom. column
- [ ] should gwas-ssf md5sum be for file immediately prior to processing?

******** Pipeline release issues

- [ ] plink2 version available through bioconda is too old, doesn't have --r2-phased program like the more recent binaries

** TODO Setting up the pipeline

Probably best to do this by copying code from the =igad_paper_pipeline=, the =conda= version.

- [X] delete redundant =smk= files
- [X] delete redundant =conda= environments
- [X] set up R package with code for meta-analysis etc.
- [-] use EBISPOT pipeline? Seems more defensible than rolling my own
  - [X] write out results to target directory; params.out_dir is not working
  - [X] fix problem of =work= directory which is not cleaned up in =harmonise_gwas= rule
  - [ ] cache EBISPOT/gwas-sumstats-harmoniser image once
  - [ ] determine list of columns which are 'minimal' for our purposes
  - [-] troubleshoot problematic sources
    - [-] check all headers for =rsid=-like column
    - [-] eldjarn
      - [-] format all
        - [-] problem with not reformatting =otherAllele= to =other_allele=
          - [ ] fix programmatically
          - [X] handle in ad hoc manner
            - [X] iga
            - [X] igg
            - [X] igm
        - [X] relabelling rsids to rsid (Hmmmm probably shouldn't, actually! Has ;-delimited values)
          - [X] should =gwas-ssf= handle this better?
          - [X] how are comma-separated rsIDs handled in this field? I.e. do we just drop everything with multiple rsIDs?
      - [X] igm
      - [X] igg
      - [X] iga
    - [X] EPIC
      - [X] format all
      - [X] igm
      - [X] igg
      - [X] iga
    - [X] pietzner
    - [X] scepanovic
    - [X] gudjonsson
    - [X] dennis
- [ ] suggestions for =gwas-ssf=
  - [ ] handle =otherAllele= to =other_allele=, see =eldjarn-iga=
    - maybe the issue is due to there being both =other_allele= and =otherAllele= in the raw file?
  - [ ] handle =chr= prefix in chrom column
    - [ ] run through validate step to see if this triggers anything
  - [ ] =rsids= handling
- [ ] submit PR for fix to concatenation issue
- [-] =sdY= standardisation is going to have to take place after harmonisation
  - [X] code to estimate sdY
  - [ ] copy over requisite 1kGP =merged.afreq= and =prune.in=
  - [ ] merge harmonised stats with LD-pruned set with MAF
  - [ ] write down the fact we used European 1kGP3 MAFs to estimate the sdY values for the sake of the Methods; this is an issue wrt. Icelandic samples

*** TODO Harmonised columns

- chromosome
- base_pair_location
- variant_id
- rsid
- effect_allele
- other_allele
- effect_allele_frequency (I believe this is usually absent, isn't calculated from reference)
- beta
- standard_error
- p_value

I believe there are =hm_=-prefixed columns, too.

*** Troubleshooting
**** TODO =pietzner-igg= stopping short <2024-11-18 Mon>

Is this because it doesn't need to be harmonised? Is the =meta.yml= configuring the run incorrectly?

Job stops after =ten_percent_counts=. The next step is =ten_percent_counts_sum=. This is invoked at line 51 in =major_direction.nf=.

Able to map most variants to build.

Maybe because the input file is not sorted? No, =liu-iga.tsv= was not sorted but I could process it. I had misnamed it as =pietzner-iga= in the =meta.yaml= file but I do not think that would change anything.

Running with =local= executor has it stop at =ten_percent_counts=.

Running with =executor= executor has it fail on =ten_percent_counts_sum=. See the relevant =.nextflow.log= next.

Running with =conda,singularity= (rather than =local,conda=) actually did allow it to progress, but then it failed for want of =pandas= in the environment.

Creating the =gwas_harm= environment; nextflow isn't available in this environment, though. Having to modify the version of PyYAML that they suggest.

Running with just the =conda= profile: stops at =ten_percent_counts=. Doing the same for 1-22 gets me to =concatenate_chr_splits=, at which point it fails on =chrMT=; this was when I ran the local checkout of the pipeline.

=pietzner-igg= is a big file; maybe run with more memory?

Now debugging by running my own fork of the pipeline.
#+begin_src
ten_to_sum=ten_percent_counts.out
                      .ten_sc
                      .groupTuple(by: 0)
                      .branch{pass:it[1].size()==nchr}
                      .map{it[0]}
#+end_src

The =branch= is the problem: I set the =chromlist= to =21,22=, checked that =nchr= was 2, and then got to the =branch= to find... tails off here. Was it 25?

We have chromosomes 1-23 in the file, I wonder if that is the issue. We still get =1 of 25= etc. in the =ten_percent_counts= step, stops after this, apparently =chromlist= makes no difference.

Running with =conda= and no =chromlist= gets it past the =ten_percent_counts_sum=.

What if I filtered it so we had only chromosomes 1-22?

Maybe I could fix that step later in the pipeline that doesn't allow concatenation of the empty file?

#+begin_quote
executor >  local (51)
[86/3c7586] NFC…ap_to_build (pietzner-igg) | 1 of 1 ✔
[32/205e9e] NFC…counts (pietzner-igg_chr7) | 25 of 25 ✔
[78/60c970] NFC…_counts_sum (pietzner-igg) | 1 of 1 ✔
[-        ] NFC…ion:generate_strand_counts -
[-        ] NFC…on:summarise_strand_counts -
[9b/c9ec06] NFC…zation (pietzner-igg_chr7) | 15 of 25
[-        ] NFC…arm:concatenate_chr_splits -
[-        ] NFC…LOGHARM:quality_control:qc -
[-        ] NFC…_control:harmonization_log -
[-        ] NFC…y_control:update_meta_yaml -
ERROR ~ Error executing process > 'NFCORE_GWASCATALOGHARM:GWASCATALOGHARM:main_harm:harmonization (pietzner-igg_chrMT)'

Caused by:
  Process `NFCORE_GWASCATALOGHARM:GWASCATALOGHARM:main_harm:harmonization (pietzner-igg_chrMT)` terminated with an error exit status (1)


Command executed:

  coordinate_system=$(grep coordinate_system pietzner-igg.tsv-meta.yaml | awk -F ":" '{print $2}' | tr -d "[:blank:]" )
  if test -z "$coordinate_system"; then coordinate="1-based"; else coordinate=$coordinate_system; fi
  
  header_args=$(utils.py -f MT.merged -harm_args);
  
  main_pysam.py     --sumstats MT.merged     --vcf /rds/project/rds-HNdhZnUvWRk/analysis/pid/common_variant_analysis/serum_ig_pipeline/resources/ebispot_harmoniser/reference/homo_sapiens-chrMT.vcf.gz     --hm_sumstats chrMT.merged_unsorted.hm     --hm_statfile chrMT.merged.log.tsv.gz     $header_args     --na_rep_in NA     --na_rep_out NA     --coordinate $coordinate     --palin_mode forward;
  
  chr=$(awk -v RS='     ' '/chromosome/{print NR; exit}' chrMT.merged_unsorted.hm)
  pos=$(awk -v RS='     ' '/base_pair_location/{print NR; exit}' chrMT.merged_unsorted.hm)
  
  head -n1 chrMT.merged_unsorted.hm > chrMT.merged.hm;
  tail -n+2 chrMT.merged_unsorted.hm | sort -n -k$chr -k$pos -T$PWD >> chrMT.merged.hm

Command exit status:
  1

Command output:
  (empty)

Command error:
  Traceback (most recent call last):
    File "/rds/project/rds-HNdhZnUvWRk/analysis/pid/common_variant_analysis/gwas-sumstats-harmoniser/bin/main_pysam.py", line 780, in <module>                                                
      main()
    File "/rds/project/rds-HNdhZnUvWRk/analysis/pid/common_variant_analysis/gwas-sumstats-harmoniser/bin/main_pysam.py", line 34, in main                                                     
      out_header = SumStatsTable(sumstats_file=args.sumstats)._set_header_order()
    File "/rds/project/rds-csoP2nj6Y6Y/tw395/mambaforge/envs/gwas_harm/lib/python3.9/site-packages/gwas_sumstats_tools/interfaces/data_table.py", line 188, in _set_header_order              
      header_order.extend([h for h in self.FIELDS_OPTIONAL if h in self.header()])
    File "/rds/project/rds-csoP2nj6Y6Y/tw395/mambaforge/envs/gwas_harm/lib/python3.9/site-packages/gwas_sumstats_tools/interfaces/data_table.py", line 188, in <listcomp>                     
      header_order.extend([h for h in self.FIELDS_OPTIONAL if h in self.header()])
    File "/rds/project/rds-csoP2nj6Y6Y/tw395/mambaforge/envs/gwas_harm/lib/python3.9/site-packages/gwas_sumstats_tools/interfaces/data_table.py", line 226, in header                         
      if self.is_table_content():
    File "/rds/project/rds-csoP2nj6Y6Y/tw395/mambaforge/envs/gwas_harm/lib/python3.9/site-packages/gwas_sumstats_tools/interfaces/data_table.py", line 105, in is_table_content               
      return etl.nrows(self.head_table(nrows=1)) > 0
    File "/rds/project/rds-csoP2nj6Y6Y/tw395/mambaforge/envs/gwas_harm/lib/python3.9/site-packages/petl/util/counting.py", line 22, in nrows                                                  
      return sum(1 for _ in data(table))
    File "/rds/project/rds-csoP2nj6Y6Y/tw395/mambaforge/envs/gwas_harm/lib/python3.9/site-packages/petl/util/counting.py", line 22, in <genexpr>                                              
      return sum(1 for _ in data(table))
    File "/rds/project/rds-csoP2nj6Y6Y/tw395/mambaforge/envs/gwas_harm/lib/python3.9/site-packages/petl/transform/basics.py", line 751, in iterrowslice                                       
      it = iter(source)
  TypeError: 'NoneType' object is not iterable

Work dir:
  /rds/project/rds-HNdhZnUvWRk/analysis/pid/common_variant_analysis/serum_ig_pipeline/results/gwas/gwas_ssf/work/df/4e35b098446f858482b55c44073655                                            

Tip: view the complete command output by changing to the process work dir and entering the command `cat .command.out`                                                                         

 -- Check '.nextflow.log' file for details

#+end_quote

Need to edit the above to run the =header_args= and =main_pysam.py= lines. Probably easier to get the paths etc. by writing the commands in a script.

It's definitely the =main_pysam.py= script that is causing problems:
#+begin_src
if args.hm_sumstats:
      out_handle = open_gzip(args.hm_sumstats, "wb")
      out_header = SumStatsTable(sumstats_file=args.sumstats)._set_header_order()
      tag_neg_log_10_p_value=False
      if "neg_log_10_p_value" in out_header:
          out_header.remove("neg_log_10_p_value")
          tag_neg_log_10_p_value=True
#+end_src

Problem is that there are no rows in =MT.merged=, the file to which =args.sumstats=.

***** Creating issue

Note:
- x of 25 when I'm only specifying 1-22
- stops after =ten_percent_counts=
- if they ask why I'm not restricting it to 1-22, say it's because I got further with the default setting and got an explicit error rather than an orderly exit after the =ten_percent_counts= stage

**** DONE Fixing =gwas_harm= environment

Looks like some of the pip dependencies conflict with those of the updated =gwas-sumstats-tools=

****** PR

- reference Vietnamese guy's PR, say doing the same but with the latest release of =gwas-sumstats-tools=
- updated =PyYAML=, =requests=, and specified a version for =numpy=, issue previously encountered https://github.com/EBISPOT/gwas-sumstats-tools/issues/45

***** Looking at this issue for =eldjarn-igg=

The =eldjarn-igg= data set progressed to writing out =ten_percent_total_strand_count.tsv=:
#+begin_quote
Palindromic variant     0
Forward strand variant  0
Reverse strand variant  0
No VCF record found     0
Invalid variant for harmonisation       0
palin_mode      drop
#+end_quote

This file is written out by =ten_percent_counts_sum.nf=. Looks like all the variants are in the =1_map_to_build/unmapped= file!

**** Test job also stopping short <2024-12-04 Wed>

Job stopping at =ten_percent_counts= as before.

This happened when I ran:
#+begin_src
nextflow -c /rds/project/rds-HNdhZnUvWRk/analysis/pid/common_variant_analysis/serum_ig_pipeline/config/harmoniser.config run /rds/project/rds-HNdhZnUvWRk/analysis/pid/common_variant_analysis/gwas-sumstats-harmoniser --ref /rds/project/rds-HNdhZnUvWRk/analysis/pid/common_variant_analysis/serum_ig_pipeline/resources/ebispot_harmoniser/reference -profile test,conda
#+end_src

Not sure why it does not work with =conda=: stopping after the =ten_percent_counts= step. Maybe because I'm rerunning it before deleting the previous output?

Trying to reproduce this with default settings (i.e. =test,singularity=) after dropping the =-c= argument but still running my local checkout of the harmoniser (65714615).
#+begin_src
nextflow run /rds/project/rds-HNdhZnUvWRk/analysis/pid/common_variant_analysis/gwas-sumstats-harmoniser --ref /rds/project/rds-HNdhZnUvWRk/analysis/pid/common_variant_analysis/serum_ig_pipeline/resources/ebispot_harmoniser/reference -profile test,singularity
#+end_src

#+begin_src
executor >  local (26)
[25/26245c] NFC…map_to_build (random_name) | 1 of 1 ✔
[a4/039746] NFC…_counts (random_name_chrX) | 25 of 25 ✔
[-        ] NFC…ion:ten_percent_counts_sum -
[-        ] NFC…ion:generate_strand_counts -
[-        ] NFC…on:summarise_strand_counts -
[-        ] NFC…RM:main_harm:harmonization -
[-        ] NFC…arm:concatenate_chr_splits -
[-        ] NFC…LOGHARM:quality_control:qc -
[-        ] NFC…_control:harmonization_log -
[-        ] NFC…y_control:update_meta_yaml -
Completed at: 04-Dec-2024 21:48:45
Duration    : 17m 47s
CPU hours   : 0.3
Succeeded   : 26
#+end_src

This still happens if I run it in a separate directory, =test=.

Running with the repo version (65726143):
#+begin_src
nextflow run EBISPOT/gwas-sumstats-harmoniser --ref /rds/project/rds-HNdhZnUvWRk/analysis/pid/common_variant_analysis/serum_ig_pipeline/resources/ebispot_harmoniser/reference -r $release_version -profile test,singularity
#+end_src

Hadn't set =release_version= (v1.1.10).

Had to delete the =.nextflow= directory to get this running; would this help with the other jobs?

Ok, =conda= version does not work even with this! Stops at =ten_percent_counts=.

I can run these on my own machine, might be due to the cluster.

***** Running the =test= locally

This works?
#+begin_src
  (base) tomw@toms-tpd:~/cam/serum_ig_pipeline$ sudo nextflow run EBISPOT/gwas-sumstats-harmoniser -r v1.1.10 -profile test,singularity
Nextflow 24.10.2 is available - Please consider updating your version to it

 N E X T F L O W   ~  version 24.10.0

Pulling EBISPOT/gwas-sumstats-harmoniser ...
 downloaded from https://github.com/EBISPOT/gwas-sumstats-harmoniser.git
Launching `https://github.com/EBISPOT/gwas-sumstats-harmoniser` [special_pike] DSL2 - revision: 436c17a91c [v1.1.10]

Start harmonising files
Harmonizing the file /root/.nextflow/assets/EBISPOT/gwas-sumstats-harmoniser/test_data/random_name.tsv
[-        ] process > NFCORE_GWASCATALOGHARM:GWASCATALOGHARM:major_direction:map_to_build            -
executor >  local (10)
[dd/b4e1e8] process > NFCORE_GWASCATALOGHARM:GWASCATALOGHARM:major_direction:map_to_build (random_name)             [100%] 1 of 1 ✔
[08/76cf43] process > NFCORE_GWASCATALOGHARM:GWASCATALOGHARM:major_direction:ten_percent_counts (random_name_chr1)  [100%] 2 of 2 ✔
[8c/2a1791] process > NFCORE_GWASCATALOGHARM:GWASCATALOGHARM:major_direction:ten_percent_counts_sum (random_name)   [100%] 1 of 1 ✔
[-        ] process > NFCORE_GWASCATALOGHARM:GWASCATALOGHARM:major_direction:generate_strand_counts                 -
[-        ] process > NFCORE_GWASCATALOGHARM:GWASCATALOGHARM:major_direction:summarise_strand_counts                -
[74/814d7d] process > NFCORE_GWASCATALOGHARM:GWASCATALOGHARM:main_harm:harmonization (random_name_chr22)            [100%] 2 of 2 ✔
[30/577ac7] process > NFCORE_GWASCATALOGHARM:GWASCATALOGHARM:main_harm:concatenate_chr_splits (random_name)         [100%] 1 of 1 ✔
[c1/8f7d1b] process > NFCORE_GWASCATALOGHARM:GWASCATALOGHARM:quality_control:qc (random_name)                       [100%] 1 of 1 ✔
[65/fdb023] process > NFCORE_GWASCATALOGHARM:GWASCATALOGHARM:quality_control:harmonization_log (random_name)        [100%] 1 of 1 ✔
[5d/7422ca] process > NFCORE_GWASCATALOGHARM:GWASCATALOGHARM:quality_control:update_meta_yaml (random_name)         [100%] 1 of 1 ✔
Completed at: 04-Dec-2024 18:03:32
Duration    : 1m 29s
CPU hours   : (a few seconds)
Succeeded   : 10
#+end_src

When I run my checkout, it finishes those missing jobs too when run with =singularity=.

**** Running =eldjarn-iga= <2024-12-05 Thu>

#+begin_src
[e1/8b66a5] NFC…nization_log (eldjarn-iga) | 1 of 1, failed: 1 ✘
[-        ] NFC…y_control:update_meta_yaml -
ERROR ~ Error executing process > 'NFCORE_GWASCATALOGHARM:GWASCATALOGHARM:quality_control:harmonization_log (eldjarn-iga)'

Caused by:
  Process `NFCORE_GWASCATALOGHARM:GWASCATALOGHARM:quality_control:harmonization_log (eldjarn-iga)` terminated with an error exit status (1)


Command executed:

  # Generating running log
  log_script.sh     -r "/rds/project/rds-HNdhZnUvWRk/analysis/pid/common_variant_analysis/serum_ig_pipeline/resources/ebispot_harmoniser/reference/homo_sapiens-chr15.vcf.gz"     -i eldjarn-ig
a.tsv     -c ten_percent_total_strand_count.tsv     -d report.txt     -h harmonised.tsv     -u unmapped     -o eldjarn-iga.running.log     -p v1.1.10
  
  N=$(awk -v RS='       ' '/hm_code/{print NR; exit}' harmonised.qc.tsv)
  sed 1d harmonised.qc.tsv| awk -F "    " '{print $'"$N"'}' | creat_log.py >> eldjarn-iga.running.log
  
  # extract harmonise result
  result=$(grep Result eldjarn-iga.running.log | cut -f2)
  
  # Prepare the gzip data
  chr=$(awk -v RS='     ' '/chromosome/{print NR; exit}' harmonised.qc.tsv)
  pos=$(awk -v RS='     ' '/base_pair_location/{print NR; exit}' harmonised.qc.tsv)
  
  cat harmonised.qc.tsv | bgzip -c > eldjarn-iga.h.tsv.gz
  tabix -c N -S 1 -f -s $chr -b $pos -e $pos eldjarn-iga.h.tsv.gz

Command exit status:
  1

Command output:
  /rds/project/rds-HNdhZnUvWRk/analysis/pid/common_variant_analysis/serum_ig_pipeline/resources/ebispot_harmoniser/reference/homo_sapiens-chr15.vcf.gz,eldjarn-iga.tsv,ten_percent_total_strand_count.tsv,report.txt,harmonised.tsv,unmapped,,,eldjarn-iga.running.log,v1.1.10

Command error:
  INFO:    Environment variable SINGULARITYENV_TMP is set, but APPTAINERENV_TMP is preferred
  INFO:    Environment variable SINGULARITYENV_TMPDIR is set, but APPTAINERENV_TMPDIR is preferred
  INFO:    Environment variable SINGULARITYENV_NXF_TASK_WORKDIR is set, but APPTAINERENV_NXF_TASK_WORKDIR is preferred
  /rds/project/rds-HNdhZnUvWRk/analysis/pid/common_variant_analysis/serum_ig_pipeline/resources/ebispot_harmoniser/reference/homo_sapiens-chr15.vcf.gz,eldjarn-iga.tsv,ten_percent_total_strand_count.tsv,report.txt,harmonised.tsv,unmapped,,,eldjarn-iga.running.log,v1.1.10
  awk: line 1: syntax error at or near }
  Traceback (most recent call last):
    File "/bin/creat_log.py", line 43, in <module>
      success_ratio=success_all/all
  ZeroDivisionError: division by zero
  

#+end_src

Looks like the issue is that the chromosome values are prefixed with =chr=.

Now running after fixing =chr= issue: 65782694.

Only 2,474,741 rows in the harmonised file, though. =10_percent_ratio= ('forward sites ratio') was 0.54, which meant palindromic variants were dropped. Only harmonised 7.81% of sites. 79.93% of input variants dropped as no match in the reference VCF, but far more were still mapped to hg38.

#+begin_src
  X	NA	G	A	0.0974	0.092386	NA	0.291759	chrX:156029849:G:A	.	A	0.53498	30695	0.00198	NA	NA
X	NA	C	C	-0.0513	0.123768	NA	0.678518	chrX:156029857:C:C	.	C	0.16844	30695	0.00094	NA	NA
X	NA	G	C	0.0513	0.123768	NA	0.678518	chrX:156029857:G:C	rs1384946096	C	0.16844	30695	0.00094	NA	NA
X	NA	C	CTTAGGG	-0.0061	0.063531	NA	0.923508	chrX:156029886:C:CTTAGGG	rs1440518544	CTTAGGG	0.03456	30695	0.00348	NA	NA
X	NA	T	T	0.0029	0.060766	NA	0.961936	chrX:156029888:T:T	.	T	0.01685	30695	0.00355	NA	NA
X	NA	*	T	-0.0029	0.059369	NA	0.961041	chrX:156029888:*:T	.	T	0.01726	30695	0.00355	NA	NA
X	NA	C	G	1.0176	0.434783	NA	0.019259	chrX:156029914:C:G	rs1301486121	G	1.71537	30695	0.00022	NA	NA
X	NA	C	G	-0.0193	0.05453	NA	0.723388	chrX:156029926:C:G	rs1378190828	G	0.14063	30694	0.0051	NA	NA
X	NA	A	G	-0.0351	0.056235	NA	0.532518	chrX:156029943:A:G	rs868390234	G	0.27367	30694	0.0049	NA	NA
X	NA	A	G	-0.0351	0.05618	NA	0.532119	chrX:156029949:A:G	rs867012337	G	0.27399	30694	0.0049	NA	NA
#+end_src

If I grep for the position of the last variant in the above subset of rows, I get a match for alleles, rsID, etc.

#+begin_src
  snakemake) [tw395@login-q-1 reference]$ zcat homo_sapiens-chrX.vcf.gz | grep "156029949"
X	156029949	rs1381077572	G	GG	.	.	dbSNP_151;TSA=insertion
X	156029949	rs867012337	A	C,G	.	.	dbSNP_151;TSA=SNV;E_Freq;E_TOPMed;E_gnomAD

#+end_src

Would it be any different if I relabelled the =rsids= column? Running this as 65787288. This works!

***** =other_allele= not relabelled properly <2024-12-05 Thu>

The =eldjarn-iga.json= file 'relabels' =otherAllele= as =otherAllele= rather than =other_allele=.

#+begin_quote
Chrom   Pos     Name    rsids   effectAllele    otherAllele     Beta    Pval    minus_log10_pval        SE      N       ImpMAF
#+end_quote

=effectAllele= is handled correctly.

Actually happened again on <2025-01-24 Fri>.

****** PR for this issue

Would need to edit header schema. =otherAllele= is absent, but perhaps the matching checks for capitalised/uncapitalised versions. Main problem is that it's not picked up when generating the json.

***** =rsid= column where multiple rsIDs are present <2024-12-06 Fri>

There are 1,252,336 rows in the file with the comma-delimited rsIDs (33,449,991 rows in total).

=unmapped= has 445,802 rows, 49,740 instances of commas (more than one in some fields).

I lose just over 20% sites in total from 33.5M variants. Hmmm...

#+begin_quote
6. Failed harmonisation

21.63% ( 7139118 of 33004201 ) sites failed to harmonise.

hm_code Number  Percentage      Explanation
15      3370190 10.21%  No matching variants in reference VCF; Cannot harmonise
14      3767139 11.41%  Required fields are not known; Cannot harmonise
16      1789    0.01%   Multiple matching variants in reference VCF (ambiguous); Cannot harmonise

#+end_quote

Are we losing those code 15's for a good reason? Looking at the files in =4_harmonization=, looks like a lot of those I am losing are indels, SNPs missing information.

Does the coordinate-based step in =map_to_build.py= save any rows with multiple rsIDs? There should be some in the =eldjarn-iga= output file:
#+begin_quote
> dat[, .N, by = hm_coordinate_conversion]
   hm_coordinate_conversion        N
                     <char>    <int>
1:                       lo   118768
2:                       rs 25746315
> dat[rsid %like% ',']
Empty data.table (0 rows and 17 cols): chromosome,base_pair_location,effect_allele,other_allele,beta,standard_error...
#+end_quote

Maybe the rsID is updated? Apparently so, I get 6,717 rows, e.g.
#+begin_quote
> merged[!is.na(rsid.y)][, .(chromosome, base_pair_location, rsid.x, rsid.y)]
      chromosome base_pair_location       rsid.x
          <char>              <int>       <char>
   1:          1          112568861  rs377429784
   2:          1          151781328  rs550995792
   3:          1          166716818  rs143243322
   4:         10           91154560  rs780262309
   5:         11             197169    rs5789177
  ---                                           
6713:          9           39093202  rs375232468
6714:          9           39152534 rs1198576337
6715:          9           39209599  rs372042997
6716:          9           39465460 rs1437888070
6717:          9          102285530   rs78170949
                                   rsid.y
                                   <char>
   1:             rs377429784,rs869255253
   2: rs1491351417,rs550995792,rs60652277
   3:              rs143243322,rs60040574
   4:             rs750427664,rs780262309
   5:                 rs3839961,rs5789177
  ---                                    
6713:              rs375232468,rs60208177
6714:              rs1198576337,rs4062758
6715:              rs372042997,rs60690302
6716:             rs1437888070,rs77517622
6717:              rs398096568,rs78170949
#+end_quote

Well, good job, EBI, this was a problem I did not need to fix, I think.

**** TODO Is =rsid=-like column present elsewhere? <2024-12-06 Fri>

#+begin_src
  dennis-iga.tsv
chromosome	variant_id	base_pair_location	A1	A2	N	AF1	BETA	SE	p_value
dennis-igg.tsv
chromosome	variant_id	base_pair_location	A1	A2	N	AF1	BETA	SE	p_value
eldjarn-iga.tsv
Chrom	Pos	Name	rsids	effectAllele	otherAllele	Beta	Pval	minus_log10_pval	SE	N	ImpMAF
eldjarn-igg.tsv
Chrom	Pos	Name	rsids	effectAllele	otherAllele	Beta	Pval	minus_log10_pval	SE	N	ImpMAF
eldjarn-igm.tsv
Chrom	Pos	Name	rsids	effectAllele	otherAllele	Beta	Pval	minus_log10_pval	SE	N	ImpMAF
gudjonsson-iga.tsv
variant_id	p_value	chromosome	base_pair_location	effect_allele	other_allele	effect_allele_frequency	beta	standard_error	odds_ratio	ci_lower	ci_upper
gudjonsson-igg.tsv
variant_id	p_value	chromosome	base_pair_location	effect_allele	other_allele	effect_allele_frequency	beta	standard_error	odds_ratio	ci_lower	ci_upper
gudjonsson-igm.tsv
variant_id	p_value	chromosome	base_pair_location	effect_allele	other_allele	effect_allele_frequency	beta	standard_error	odds_ratio	ci_lower	ci_upper
iga.tsv
chr	rsid	pos	REF	ALT	all_AA	all_AB	all_BB	maf	hwe	p_value	beta	se	info_impute	impute	N
igg.tsv
chr	rsid	pos	REF	ALT	all_AA	all_AB	all_BB	maf	hwe	p_value	beta	se	info_impute	impute	N
igm.tsv
chr	rsid	pos	REF	ALT	all_AA	all_AB	all_BB	maf	hwe	p_value	beta	se	info_impute	impute	N
liu-decode-iga.tsv
SNP	CHR	BP_hg19	A1	A2	BETA	SE	P
liu-iga.tsv
SNP	CHR	BP_hg19	A1	A2	BETA	SE	P
pietzner-iga.tsv
rsid	MarkerName	Allele1	Allele2	Freq1	FreqSE	MinFreq	MaxFreq	Effect	StdErr	Pvalue	Direction	HetISq	HetChiSq	HetDf	HetPVal	TotalSampleSize	chr	pos
pietzner-igg.tsv
rsid	MarkerName	Allele1	Allele2	Freq1	FreqSE	MinFreq	MaxFreq	Effect	StdErr	Pvalue	Direction	HetISq	HetChiSq	HetDf	HetPVal	TotalSampleSize	chr	pos
pietzner-igm.tsv
rsid	MarkerName	Allele1	Allele2	Freq1	FreqSE	MinFreq	MaxFreq	Effect	StdErr	Pvalue	Direction	HetISq	HetChiSq	HetDf	HetPVal	TotalSampleSize	chr	pos
scepanovic-iga.tsv
chromosome	base_pair_location	variant_id	other_allele	effect_allele	effect_allele_frequency	test	obs_ct	beta	standard_error	t_stat	p_value	ci_upper	odds_ratio	ci_lower
scepanovic-igg.tsv
chromosome	base_pair_location	variant_id	other_allele	effect_allele	effect_allele_frequency	test	obs_ct	beta	standard_error	t_stat	p_value	ci_upper	ci_lower	odds_ratio
scepanovic-igm.tsv
chromosome	base_pair_location	variant_id	other_allele	effect_allele	effect_allele_frequency	test	obs_ct	beta	standard_error	t_stat	p_value	odds_ratio	ci_lower	ci_upper

#+end_src

Ensuring that we've handled these columns correctly where necessary:
- [-] eldjarn
  - [ ] missing rows where we have multiple rsIDs; how come we don't just use coordinates there? Apparently =map_to_build= does do this.
- [ ] EPIC
- [ ] pietzner

**** TODO Using config to specify column labels <2024-12-23 Mon>

#+begin_quote
gwas/plot_gwas_manhattan.R:chr_col <- snakemake@params[['chr_col']]
gwas/plot_gwas_manhattan.R:bp_col <- snakemake@params[['bp_col']]
gwas/plot_gwas_manhattan.R:p_col <- snakemake@params[['p_col']]
gwas/plot_gwas_manhattan.R:snp_col <- snakemake@params[['snp_col']]
gwas/lead_snp_annotation.py:chr_col = snakemake.params.chr_col
gwas/lead_snp_annotation.py:bp_col = snakemake.params.bp_col
gwas/lead_snp_annotation.py:snp_col = snakemake.params.snp_col
gwas/lead_snp_annotation.py:ref_col = snakemake.params.ref_col
gwas/lead_snp_annotation.py:alt_col = snakemake.params.alt_col
gwas/join_pair_gwas_stats.R:chr_col <- snakemake@params[['chr_col']]
gwas/join_pair_gwas_stats.R:bp_col <- snakemake@params[['bp_col']]
gwas/join_pair_gwas_stats.R:ref_col <- snakemake@params[['ref_col']]
gwas/join_pair_gwas_stats.R:alt_col <- snakemake@params[['alt_col']]
gwas/join_pair_gwas_stats.R:p_col <- snakemake@params[['p_col']]
gwas/join_pair_gwas_stats.R:beta_col <- snakemake@params[['beta_col']]
gwas/join_pair_gwas_stats.R:se_col <- snakemake@params[['se_col']]
gwas/join_pair_gwas_stats.R:id_col <- snakemake@params[['id_col']]
gwas/make_plink_range.R:chr_col <- snakemake@params[['chr_col']]
gwas/make_plink_range.R:bp_col <- snakemake@params[['bp_col']]
gwas/make_plink_range.R:ref_col <- snakemake@params[['ref_col']]
gwas/make_plink_range.R:alt_col <- snakemake@params[['alt_col']]
gwas/distance_clump.R:chr_col <- snakemake@params[['chr_col']]
gwas/distance_clump.R:bp_col <- snakemake@params[['bp_col']]
gwas/distance_clump.R:ref_col <- snakemake@params[['ref_col']]
gwas/distance_clump.R:alt_col <- snakemake@params[['alt_col']]
gwas/distance_clump.R:snp_col <- snakemake@params[['snp_col']]
gwas/distance_clump.R:p_col <- snakemake@params[['p_col']]
gwas/distance_clump.R:beta_col <- snakemake@params[['beta_col']]
gwas/distance_clump.R:se_col <- snakemake@params[['se_col']]
ldsc_and_sumher/preprocess_sumstats.R:chr_col <- snakemake@params[['chr_col']]
ldsc_and_sumher/preprocess_sumstats.R:bp_col <- snakemake@params[['bp_col']]
ldsc_and_sumher/preprocess_sumstats.R:ref_col <- snakemake@params[['ref_col']]
ldsc_and_sumher/preprocess_sumstats.R:alt_col <- snakemake@params[['alt_col']]
ldsc_and_sumher/preprocess_sumstats.R:p_col <- snakemake@params[['p_col']]
ldsc_and_sumher/preprocess_sumstats.R:beta_col <- snakemake@params[['beta_col']]
ldsc_and_sumher/preprocess_sumstats.R:snp_col <- snakemake@params[['snp_col']]
ldsc_and_sumher/process_sum_stats_for_merged_gwas.R:chr_col <- snakemake@params[['chr_col']]
ldsc_and_sumher/process_sum_stats_for_merged_gwas.R:bp_col <- snakemake@params[['bp_col']]
ldsc_and_sumher/process_sum_stats_for_merged_gwas.R:ref_col <- snakemake@params[['ref_col']]
ldsc_and_sumher/process_sum_stats_for_merged_gwas.R:alt_col <- snakemake@params[['alt_col']]
ldsc_and_sumher/process_sum_stats_for_merged_gwas.R:beta_a_col <- snakemake@params[['beta_a_col']]
ldsc_and_sumher/process_sum_stats_for_merged_gwas.R:beta_b_col <- snakemake@params[['beta_b_col']]
ldsc_and_sumher/process_sum_stats_for_merged_gwas.R:se_a_col <- snakemake@params[['se_a_col']]ldsc_and_sumher/process_sum_stats_for_merged_gwas.R:se_b_col <- snakemake@params[['se_b_col']]
#+end_quote

Need to replace the likes of =snakemake@params[['chr_col']]= with =snakemake@config$chr_col=

*** Notes on harmoniser pipeline
**** Process

***** =map_to_build=

Updates variant's position by mapping rsID to Ensembl reference. If not possible, liftover is used.

Variants which cannot be mapped are put in =1_map_to_build/unmapped=.

***** =ten_sc=

This infers strand orientation by using a 'strand consensus approach' in order to deal with palindromic variants. It looks at 10% of non-palindromic variants, selected at random, comparing them to the Ensembl VCF reference.

***** What is relevant to the handling of rsID synonyms? <2024-12-20 Fri>

****** =make_synonym_table.py=

This script is invoked in =make_local_synonyms_table=, used to create =rsID.sql=. Can we use the information in that?

=basic_qc_nf.py= takes the =rsID.sql= file as its 'synonyms' database.

#+begin_src
sqlite> .schema
CREATE TABLE variation_synonym (
    variation_id int(10)  NOT NULL,
    name varchar(255) DEFAULT NULL
    );
CREATE INDEX rsid_idx on variation_synonym (name);
CREATE INDEX syn_idx on variation_synonym (variation_id);
sqlite> PRAGMA table_info(variation_synonym)
   ...> 
   ...> ;
0|variation_id|int(10)|1||0
1|name|varchar(255)|0|NULL|0
#+end_src

It looks like this doesn't store alternatives, the following did not return any rows:

#+begin_src
sqlite> select * from variation_synonym where name like '%,%' limit 1;
#+end_src

****** =vcf= file

This stores rsIDs and some are duplicated for a given position.

****** Selecting the best rsIDs from duplicates

*** How do I have the harmoniser running on CSD3 as of <2024-12-22 Sun>?

I run =gwas-ssf= then the likes of:
#+begin_src
cd /rds/project/rds-HNdhZnUvWRk/analysis/pid/common_variant_analysis/serum_ig_pipeline/results/gwas/gwas_ssf/eldjarn-iga

conda activate gwas_harm

nextflow -c /rds/project/rds-HNdhZnUvWRk/analysis/pid/common_variant_analysis/serum_ig_pipeline/config/harmoniser.config run /rds/project/rds-HNdhZnUvWRk/analysis/pid/common_variant_analysis/gwas-sumstats-harmoniser --ref /rds/project/rds-HNdhZnUvWRk/analysis/pid/common_variant_analysis/serum_ig_pipeline/resources/ebispot_harmoniser/reference --harm --file /rds/project/rds-HNdhZnUvWRk/analysis/pid/common_variant_analysis/serum_ig_pipeline/results/gwas/gwas_ssf/eldjarn-iga/eldjarn-iga.tsv -profile singularity
#+end_src

NB:

1. my =harmoniser.config=
2. my fork of the =gwas-sumstats-harmoniser=
3. =singularity= profile

Re: 2, if my fix to the strand counts step was merged in through a PR, I could probably revert to using the public version.

** Study inclusion
*** Scepanovic and sdY estimates <2025-01-10 Fri>

There are only 1,000 subjects in this study, so inclusion is hardly critical to the power of the meta-analysis.

[[https://genomemedicine.biomedcentral.com/articles/10.1186/s13073-018-0568-8#Sec2][From the paper]]:

#+begin_quote
For single-variant association analyses, we only considered SNPs with a MAF of > 5% (N = 5,699,237). We used PLINK (v1.9) [24] to perform logistic regression for binary phenotypes (serostatus: antibody positive versus negative) and linear regression for continuous traits (log10-transformed quantitative measurements of antibody levels in seropositive donors). The first two principal components of a PCA based on genetic data, age and sex, were used as covariates in all tests. In order to correct for baseline difference in IgG production in individuals, total IgG levels were included as covariates when examining associations with antigen-specific antibody levels, total IgM, IgE, and IgA levels. From a total of 53 additional variables additional co-variates, selected by using elastic net [25] and stability selection [26] as detailed elsewhere [16], were included in some analyses (Additional file 1: Table S3). For all genome-wide association studies, we used a genome-wide significant threshold (Pthreshold < 2.6 × 10−9) corrected for the number of antigens and immunoglobulin classes tested (N = 19). For specific HLA analyses, we used PLINK (v1.07) [27] to perform conditional haplotype-based association tests and multivariate omnibus tests at multi-allelic amino acid positions.
#+end_quote

I would need an estimate of the standard deviation of Y to restandardise the summary statistics. I think it's not worth it.

They do give this number, however:

#+begin_quote
To characterize the variability in humoral immune responses between healthy individuals, we measured total IgG, IgM, IgA, and IgE levels in the plasma of the 1000 donors of the Milieu Interieur (MI) cohort. After log10 transformation, total IgG, IgM, IgA, and IgE levels showed normal distributions, with a median ± sd of 1.02 ± 0.08 g/l, 0.01 ± 0.2 g/l, 0.31 ± 0.18 g/l, and 1.51 ± 0.62 UI/ml, respectively
#+end_quote

Note that these are on the log10 scale, too. The sdY.est procedure recovered the SD values pretty well:

| Isotype | Median |   SD | Median sdY.est |
|---------+--------+------+----------------|
| IgG     |   1.02 | 0.08 |          0.079 |
| IgM     |   0.01 |  0.2 |          0.193 |
| IgA     |   0.31 | 0.18 |          0.171 |

*** What about the scale of the other summary statistics? <2025-01-10 Fri>

sdY estimates:

#+begin_quote
           dataset median(sdY.est)
 1:        liu-iga 1.1675795
 2: liu-decode-iga 1.5899747
 3:     dennis-iga 0.9110791
 4:     dennis-igg 0.9345117
 5:       epic-iga 0.4996091
 6:       epic-igg 0.2871838
 7:       epic-igm 0.5358721
 8: scepanovic-igg 0.0788076
 9: scepanovic-igm 0.1933939
10: scepanovic-iga 0.1712270
11:   pietzner-igm 0.9821195
12:   pietzner-iga 1.0155681
13:   pietzner-igg 1.0145151
14: gudjonsson-igg 0.9441563
15: gudjonsson-iga 0.9342935
16: gudjonsson-igm 0.9793915
17:    eldjarn-igg 1.0449364
18:    eldjarn-iga 1.1091828
19:    eldjarn-igm 1.0969310
#+end_quote

| Study      | Transformation                                                        | Other details                                                                      |
|------------+-----------------------------------------------------------------------+------------------------------------------------------------------------------------|
| Dennis     | rank-based INT, sdY.est values suggestive of standardised Y           |                                                                                    |
| Liu        | standard-normalised residuals from regression of log Y on age and sex |                                                                                    |
| EPIC       | log Y then standardised                                               | age, sex, and 10 PC scores in linear model for GWAS                                |
| Pietzner   | rank-based INT                                                        | 'corrected for age, sex, the first ten genetic principal components and test site' |
| Gudjonsson | Box-Cox transformation                                                | age, sex, 5 PCs, and genotyping platform                                           |
| Eldjarn    | rank-based INT then extracted standard residuals                      | 'adjusted for age, sex, and sample age'                                            |
| Scepanovic | log10                                                                 | age, sex, 2 PCs                                                                   |

NB: 'INT' is inverse normal transformation, so on the scale of a standard normal. See Fig1b in the Dennis paper for where I saw this.

I suppose these are all ways of getting response variable values to be approximately ~ N(0,1). log10 and log scales differ by log(10), so standardising the betas and SEs should take care of this.

**** Dennis

#+begin_quote
In our primary analysis, we transformed lab values to fit the normal distribution to improve the performance of the linear regression models [21]. We applied the rank-based inverse normal quantile transformation to all labs, which ensured trait normality by replacing the value of each observation with its quantile from the standard normal distribution. The inverse normal quantile transformation thus preserved the rank ordering of observations, but not the values themselves, and model coefficients therefore are uninterpretable on the original scale.
#+end_quote

**** Liu

#+begin_quote
Multi-ancestry cohorts were classified into ancestry-specific strata based on global principal component analysis. In each sub-cohort, serum IgA levels were log-transformed and expressed as standard-normalized residuals from regression of log-transformed IgA levels against age and sex. We performed genome-wide association testing in each cohort for the markers that were imputed at high quality (
) using a linear regression model under additive coding of the dosage genotypes, and with adjustment for cohort-specific significant principal components (PCs) of ancestry78. To quantify potential inflation of type I error due to stratification or technical artifacts, we estimated the genomic inflation factor for each cohort but detected no substantial inflation with lambda <1.05 in each individual study. We performed a fixed-effects as well as TransMeta random effects meta-analysis to combine the results of all 17 individual cohort summary statistics using METAL79 and TransMeta21 software, respectively. All significant loci were further assessed for heterogeneity by derivation of Heterogeneity Index (I2) and by testing using Cochrane’s heterogeneity test in PLINK80. The quantile-quantile plot of the final meta-analysis showed no global departures from the expected null distribution, with the genomic inflation factor estimated at 1.016 (Supplementary Fig. 2). The genome-wide significant signals were defined by the generally accepted P < 5.0 × 10−8 and signals with P < 1.0 × 10−6 were considered as suggestive.
#+end_quote

**** EPIC

Hmmm, 'log-transformed' and then 'standardised'?

#+begin_quote
Prior to running the GWAS, samples were removed if they had: age greater than 80 years at the time of sampling; absence of genetic data; non-European ancestry; presence of relatives in the EPIC Norfolk sample as indicated by π >= 0.1875. Variants with imputation quality (info) < 0.4, Hardy-Weinberg Equilibrium p-value < 1x10-6, minor allele frequency (MAF) < 0.001, or effect size/standard error > 10 were removed. The log-transformed IgA phenotypes were standardised and the GWAS was performed using an additive model in SNPTEST (v2.5.4-beta3) incorporating age, sex, and scores on the first ten principal components of the genetic relatedness matrix.
#+end_quote

#+begin_quote
> dat[, lapply(.SD, median, na.rm = T), .SDcols = names(dat) %like% 'IG']
   IGA_CONC IGG1_CONC IGG2_CONC IGG3_CONC IGG4_CONC IGM_CONC IGG_CONC
      <num>     <num>     <num>     <num>     <num>    <num>    <num>
1: 233.9935   582.268   227.672     43.63    34.035   65.836   932.63
#+end_quote

NB: I created the =IGG_CONC= column as the sum of the IgG subclasses.

What was the sdY in the raw data? I don't know the subset of samples used for the GWAS of each isotype, I have 9,610 data points here. What is the sd of Y on different scales?

#+begin_quote
> dcast(melt(rbound, id.vars = 'scale'), variable ~ scale)[, .(variable, raw, log, log10)]
Key: <variable>
    variable       raw       log     log10
      <fctr>     <num>     <num>     <num>
1:  IGA_CONC 134.52692 0.5037606 0.2187805
2: IGG1_CONC 226.56262 0.3543768 0.1539039
3: IGG2_CONC 117.06080 0.5133363 0.2229391
4: IGG3_CONC  37.24913 0.5951565 0.2584732
5: IGG4_CONC  66.30797 1.0375210 0.4505896
6:  IGM_CONC  52.42656 0.5423559 0.2355422
7:  IGG_CONC 274.35088 0.2836292 0.1231786
#+end_quote

For what it's worth, log10 was used in that other paper. Comparing with the =sdY.est= values:

#+begin_quote
           dataset median(sdY.est)
 5:       epic-iga 0.4996091
 6:       epic-igg 0.2871838
 7:       epic-igm 0.5358721
#+end_quote

Looks like there's a very good match between the log scale values and the estimates we recover here. What about normality? Can't paste a plot in here but it looks ok. I think the location's not an issue as we have the intercept in the regression, so really it's just scale that's the issue.

**** Pietzner

#+begin_quote
Genome-wide association studies for each protein target (rank-based inverse normal-transformed aptamer abundance corrected for age, sex, the first ten genetic principal components and test site) were run for each array separately using the BGENIE software (v1.3) (74) and the results were combined in a fixed-effects meta-analysis in METAL (75). We restricted the GWAS to variants with a minor allele frequency threshold of at least 1%.
#+end_quote

More detail from their Covid paper:

#+begin_quote
After excluding ancestry outliers and related individuals, 10,708 Fenland participants had both phenotypes and genetic data for the GWAS (OMICS = 8350, Core-Exome=1026, and GWAS = 1332). Within each genotyping subset, aptamer abundances were transformed to follow a normal distribution using the rank-based inverse normal transformation. Transformed aptamer abundances were then adjusted for age, sex, sample collection site, and 10 principal components in STATA v14, and the residuals used as input for the genetic association analyses. Test site was omitted for protein abundances measured by Olink as those were all selected from the same test site. Genome-wide association was performed under an additive model using BGENIE (v1.3)45. Results for the three genotyping arrays were combined in a fixed-effects meta-analysis in METAL48. Following the meta-analysis, 17,652,797 genetic variants, also present in the largest subset of the Fenland data (Fenland-OMICS), were taken forward for further analysis.
#+end_quote

**** Gudjonsson

#+begin_quote
Data processing and statistical analysis were performed using R (v3.5.1 & 4.0.1) and Rstudio (v1.1.456), unless otherwise specified. Box-Cox transformation was applied on the protein data55 and extreme outlier values were excluded, defined as values above the 99.5th percentile of the distribution of 99th percentile cutoffs across all proteins after scaling, resulting in the removal of an average 11 samples per SOMAmer, as previously described18. Within the AGES cohort, 5368 individuals had both genetic data and protein measurements. With that sample set, 7,506,463 variants were tested for association with each of the 4782 SOMAmers separately, in a linear regression model with age, sex, 5 genetic principal components, and genotyping platform as covariates using PLINK 2.0. To obtain independent genetic signals, we performed a stepwise conditional association analysis for each SOMAmer separately with the GCTA-COJO software19,20. We conditioned on the current lead variant, defined as the variant with the lowest P-value, and then kept track of any new lead variants with study-wide-significant associations. Variants in strong LD (r2 > 0.9) with previously chosen lead variants were not considered for joint analysis to avoid multicollinearity. The independent signals defined by GCTA-COJO were subsequently subjected to a validation analysis where the joint models were tested using individual-level data in AGES and those remaining study-wide significant retained. Associations with independent lead variants within 300 kb window of the gene boundaries of the protein-coding gene were defined as cis-signals, and otherwise in trans. To compare independent signals between SOMAmers, we define any signals with lead variants in strong LD (r2 > 0.9) as the same signal. Due to the complex LD structure and high pleiotropy of the MHC region56 (chr.6, 28.47–34.45 Mb) we collapsed all signals within that region to a single signal. To define loci harboring independent signals, we defined a 300 kb window around each independent signal (150 kb up- and downstream of lead variants) and collapsed all such intersecting windows. Therefore, the definition of loci is solely based on physical distances while the definition of independent signals is solely based on LD structure. Variants were annotated using the Ensembl Variant Effect Predictor57 (v104, “per_gene” option), where PAVs affecting the corresponding protein target were defined as those with the following consequences: splice acceptor variant, splice donor variant, splice region variant, stop gained, stop lost, start lost, frameshift variant, missense variant or frameshift variant. The GWAS results were visualized using Circos58. Pathway enrichment was performed using gProfiler59, using the full set of measured proteins as background and considering Benjamini–Hochberg FDR < 0.05 as statistically significant. Enrichment of tissue-elevated gene expression was performed using data from the Human Protein Atlas24 with a Fisher’s exact test, considering Benjamini–Hochberg FDR < 0.05 as statistically significant.
#+end_quote

**** Eldjarn

#+begin_quote
Genome-wide association study

We rank-inverse normal transformed the measurements for each assay and adjusted them for age, sex and sample age. We standardized the residuals using rank-inverse normal transformation and used the standardized values as phenotypes for genome-wide association testing using a linear mixed model (BOLT-LMM71). We used LD score regression to account for inflation in test statistics due to cryptic relatedness and stratification72.

We computed P values using a likelihood ratio test and adjusted for multiple testing by using the same significance threshold (1.8 × 10−9) as in our previous study on the Icelandic dataset2.

We defined a pQTL association to be cis if the pQTL was located within 1 Mb of the transcription start site for the gene that encodes the target protein, as reported by UniProt, and trans otherwise.

Of the 2,941 assays on the Olink Explore 3072 platform, data from UKB for 2,931 assays were used for GWAS analysis.

The number of variants we test in Iceland (33.5 million) is about 40% lower than in UKB (57.7 million). The difference is largely due to very rare variants. However, the difference between them would result in a multiple testing correction threshold in UKB of 8.7 × 10−10 instead of 1.8 × 10−9. A total of 153 (1%) of the cis pQTLs are between those two thresholds and 1,608 (5%) of the trans pQTLs.

For replication between platforms, the P value threshold is 0.05, with the requirement that initial and replication associations are in the same direction.




#+end_quote

**** Scepanovic

#+begin_quote
For single-variant association analyses, we only considered SNPs with a MAF of > 5% (N = 5,699,237). We used PLINK (v1.9) [24] to perform logistic regression for binary phenotypes (serostatus: antibody positive versus negative) and linear regression for continuous traits (log10-transformed quantitative measurements of antibody levels in seropositive donors). The first two principal components of a PCA based on genetic data, age and sex, were used as covariates in all tests. In order to correct for baseline difference in IgG production in individuals, total IgG levels were included as covariates when examining associations with antigen-specific antibody levels, total IgM, IgE, and IgA levels. From a total of 53 additional variables additional co-variates, selected by using elastic net [25] and stability selection [26] as detailed elsewhere [16], were included in some analyses (Additional file 1: Table S3). For all genome-wide association studies, we used a genome-wide significant threshold (Pthreshold < 2.6 × 10−9) corrected for the number of antigens and immunoglobulin classes tested (N = 19). For specific HLA analyses, we used PLINK (v1.07) [27] to perform conditional haplotype-based association tests and multivariate omnibus tests at multi-allelic amino acid positions.
#+end_quote

*** Which data sets should I rescale? <2025-01-11 Sat>

All three =pietnzer= data sets, =gudjonsson-iga=, =eldjarn-igg= are within 0.05 of 1 (the expected sdY under N(0,1)), so I'll leave these as they are for fear of introducing more noise into them.

*** Dataset idiosyncrasies

**** Eldjarn

Need to:
- strip leading =chr= from chromosome column
- explicitly map =otherAllele= to =other_allele= in the json config
- explicitly map =rsids= to =rsid= in the json config
- specify genome assembly as GRCh38?

** TODO Z-score plots

** Existing associations

I've tabulated these in the past, but now we have two studies, Gudjonsson and Eldjarn, whose associations don't seem to be tabulated in the usual places.

** Big signals in the IGH locus
*** Which studies have these

- =eldjarn-iga= has signal labelled IGHA1
- =eldjarn-igg= has signal labelled IGHG1
- =eldjarn-igm= has signal labelled IGHG1
- =epic-iga= has signal labelled IGHA1
- =epic-igg= has signal labelled IGHG1
- =pietzner-iga= has signal labelled IGHA1
- =pietzner-igg= has signal labelled IGHG1

** Content for the paper
*** Introduction

Idea that the study of common-variant architecture of physiological trait might inform understanding of traits in which dysregulation of the same antibody isotypes is implicated. Could cite our IgAD paper here but that seems a bit obnoxious; Kiryluk/Liu paper talked about IgAN.

Idea that immune-mediated diseases and immune-related traits (which?) show evident of widespread pleiotropy, motivates interrogation of the shared genetic architecture which underlies variance in these physiological traits as well as the pathological ones.

*** Methods

Re: sdY estimation, I used a prune of the 1kGP panel of SNPs with MAF > 0.005 in Europeans (TODO check that this was data set specific). Took median of estimates, which were precise, anyway, showed good agreement with

*** Discussion

Heterogeneity among component study methods

** Miscellaneous data set-specific issues
*** To SMP or not SMP?

This is discussed in [[https://static-content.springer.com/esm/art%3A10.1038%2Fs41586-023-06563-x/MediaObjects/41586_2023_6563_MOESM1_ESM.pdf][Supplementary Note 4]]:

#+begin_quote
As a normalization step, SomaScan scales each sample to conform to a reference population. This is done by calculating a scaling factor for each assay relative to a reference sample, averaging this scaling factor over all assays in the same dilution group, and applying the resulting scaling factor to all assays in the dilution group. While this can serve to reduce variation between samples, this may not always be desirable, as this has the effect of potentially removing large-scale variation in protein levels, affecting multiple proteins. Some studies therefore forego this normalization4. Here, we briefly note how the SMP normalization affects the present analysis.
#+end_quote

They note not everyone performs SMP in their studies. This passage is quite persuasive:

#+begin_quote
Using non-normalized data, the levels of 79% of SomaScan assays associated with age and 58% 64 associated with sex (Supplementary Table ST14). The SomaScan normalization factors were associated 65 with age and sex and affected the association with the normalized data accordingly (Supplementary 66 Table ST14). The correlations between age and sex effects were less consistent between Olink and 67 SomaScan (Spearman correlation=0.53 for age and 0.57 for sex).
#+end_quote

#+begin_quote
Notably, the normalization decreases the correlation between Olink and SomaScan assays, probably because it is adjusting out some of the biological variability as previously described. However, the power to detect protein associations with sequence variants and phenotypes that are not pleiotropic tends to increase following normalization.
#+end_quote

As of <2025-01-23 Thu> I'm already in deep with the raw data.

[[https://pmc.ncbi.nlm.nih.gov/articles/PMC7744536/#Sec14][Pietzner et al.]] did perform the normalisation:

#+begin_quote
Proteomic profiling of fasted EDTA plasma samples from 12,084 Fenland Study participants collected at baseline was performed by SomaLogic Inc. (Boulder, CO, USA) using an aptamer-based technology (SomaScan proteomic assay). Relative protein abundances of 4775 human protein targets were evaluated by 4979 aptamers (SomaLogic V4), and a detailed description can be found elsehwere43. Briefly, the SomaScan assay utilizes a library of short single-stranded DNA molecules that are chemically modified to specifically bind to protein targets, and the relative amount of aptamers binding to protein targets is determined using DNA microarrays. To account for variation in hybridization within runs, hybridization control probes are used to generate a hybridization scale factor for each sample. *To control for total signal differences between samples due to variation in overall protein concentration or technical factors such as reagent concentration, pipetting, or assay timing; a ratio between each aptamer’s measured value and a reference value is computed, and the median of these ratios is computed for each of the three dilution sets (40%, 1%, and 0.005%) and applied to each dilution set.* Samples were removed if they were deemed by SomaLogic to have failed or did not meet our acceptance criteria of 0.25–4 for all scaling factors. In addition to passing SomaLogic QC, only human protein targets were taken forward for subsequent analysis (4979 out of the 5284 aptamers). Aptamers’ target annotation and mapping to UniProt accession numbers as well as Entrez gene identifiers were provided by SomaLogic.
#+end_quote

I think on that basis I should use the SMP'd Eldjarn data sets.

*** Why didn't I include the UKB Olink data sets from Eldjarn et al.?

I grepped through the =bi= directory (British and Irish ancestry GWAS in the UKB) and couldn't find any results for antibodies.

** Possibility of Eldjarn/Gudjonsson overlap <2025-01-23 Thu>

[[https://www.nature.com/articles/s41586-023-06563-x][Eldjarn et al.]] looked at >50k people from UKB using Olink and compared results with SomaScan samples from 36k Icelanders. 1,514 Icelanders also had Olink measurements.

I downloaded the SomaScan data, i.e. the Icelandic data, not the UKB data.

[[https://www.nature.com/articles/s41467-021-27850-z#Sec2][Gudjonsson et al.]] looked at 5,368 elderly Icelanders from the AGES Cohort, more on [[https://pmc.ncbi.nlm.nih.gov/articles/PMC2723948/#:~:text=The%20AGES%2DReykjavik%20sample%20is,by%20the%20Icelandic%20Heart%20Association.][them here]].

#+begin_quote
The AGES-Reykjavik sample is drawn from an established population-based cohort, the Reykjavik Study. This cohort of men and women born between 1907 and 1935 has been followed in Iceland since 1967 by the Icelandic Heart Association.
#+end_quote

Eldjarn et al. refer to an earlier paper by [[https://www.nature.com/articles/s41588-021-00978-w#Sec14][Ferkingstad et al.]], which describes the study participants:

#+begin_quote
From 24 August 2000 until 11 January 2019, we collected plasma samples from 40,004 Icelanders through two main projects: the Icelandic Cancer Project47 (52% of participants; samples collected from 2001 to 2005) and various genetic programs at deCODE genetics, Reykjavík, Iceland (48%). In the Icelandic Cancer Project, we invited all Icelanders with prevalent and newly diagnosed cancer and their relatives to participate in a comprehensive study of cancer, along with a control population, randomly selected from the National Registry. This sample set is enriched for cancer; 36% of the samples correspond to a cancer diagnosis up to the year 2019. For a given cancer, the fraction of active cancer (diagnosis from 2 years before to 1 month after sampling) out of the whole set was never higher than 1% for the 13 cancer types with at least 100 cases. The largest fraction of cases diagnosed before sampling out of the 36,000 individuals in the study was below 5% for all cancers (Supplementary Table 19). The samples collected at deCODE genetics were mainly collected through the population-based deCODE Health study, and the rest were mainly collected through various programs at deCODE. The median collection date for samples collected in the Icelandic Cancer Project was 1 July 2002, whereas the median collection date for deCODE samples was 15 May 2015. The average participant age was 55 years (s.d. = 17 years), and 57% were women. All participants who donated samples gave informed consent, and the National Bioethics Committee of Iceland approved the study, which was conducted in agreement with conditions issued by the Data Protection Authority of Iceland (VSN_14-015). Personal identities for the participant’s data and biological samples were encrypted by a third-party system (Identity Protection System), approved and monitored by the Data Protection Authority.
#+end_quote

** Downloading the deCODE data (Eldjarn et al.)

NB: remember to have up-to-date keys in =~/.aws/credentials= as supplied in the deCODE request response email.

Listing
#+begin_src
aws s3 ls s3://largescaleplasma-2023/final_somascan_raw/Proteomics_PC0_11089_7_IGHA1_IGHA2_IgA_07082019.txt.gz --endpoint-url https://s3-ext.decode.is:10443
#+end_src


#+begin_quote
aws s3 cp s3://largescaleplasma-2023/final_somascan_raw/Proteomics_PC0_11089_7_IGHA1_IGHA2_IgA_07082019.txt.gz --endpoint-url https://s3-ext.decode.is:10443

while IFS= read -r s3_url; do
  # Use aws s3 cp to download each file
  aws s3 cp "$s3_url" resources/decode_data/ --endpoint-url https://s3-ext.decode.is:10443
done < decode_files.txt
#+end_quote

Contents of the README:
#+begin_quote
These files contain GWAS summary statistics from the Icelandic SomaScan proteomics data (with and without SMP normalization),
as well as GWAS summary statistics from the UK Biobank Olink proteomics data (for British/Irish, African, and South Asian ancestries):

The different groups can be identified by the start of the file name:
GBR_UKB_Africa: UK Biobank Olink, African ancestry
GBR_UKB_OLINK: UK Biobank Olink, British/Irish ancestry
GBR_UKB_SAsia: UK Biobank Olink, South Asian ancestry
Proteomics_PC0: Icelandic SomaScan, without SMP normalization
Proteomics_SMP: Icelandic SomaScan, with SMP normalization

The columns of the GWAS summary statistics files are as follows:
Chrom: Chromosome
Pos: Position (hg38)
Name: Unique variant name
rsids: rs-name, if it exists
effectAllele: Effect allele
otherAllele: Non-effect allele
Beta: Effect (in standard deviations)
Pval: P-value
minus_log10_pval: -log10 of P-value
SE: Standard error
N: Sample size
ImpMAF: Minor allele frequency
Note: For multi-allelic variants, the value '!' in otherAllele means that the effectAllele is tested against the other (two or more) 
alleles except effectAllele (using the '!' sign as shorthand for 'not effectAllele'). 
#+end_quote

Files:
#+begin_quote
Proteomics_SMP_PC0_11089_7_IGHA1_IGHA2_IgA_10032022.txt.gz
Proteomics_SMP_PC0_3069_52_IGHM_IGJ_IGK_IGL_IgM_10032022.txt.gz
Proteomics_SMP_PC0_2744_57_IGHG1_IGHG2_IGHG3_IGHG4_IGK_IGL_IgG_10032022.txt.gz
Proteomics_SMP_PC0_13230_174_IGHG2_IgG2__Kappa_10032022.txt.gz
Proteomics_SMP_PC0_13231_90_IGHG4_IgG4__Kappa_10032022.txt.gz

aws s3 cp s3://largescaleplasma-2023/final_somascan_smp/Proteomics_SMP_PC0_2744_57_IGHG1_IGHG2_IGHG3_IGHG4_IGK_IGL_IgG_10032022.txt.g --endpoint-url https://s3-ext.decode.is:10443 .
#+end_quote

** Heritability estimation

*** BLD-LDAK model <2025-01-28 Tue>

As the preponderance of the data comes from imputed SNP data sets, I choose [[https://dougspeed.com/pre-computed-tagging-files/][the HapMap3 panel over the smaller, directly genotyped set]].

Tried to run tagging calculate for one of the 65 annotations, takes way too long!

*** Trouble after rerunning <2025-02-14 Fri>

**** Troublesome results

Earlier I got much larger estimates (h2 = 0.18 and 0.16 with/out MHC) for IgA, but now:

#+begin_quote
Component Heritability Her_SD Influence Inf_SD
Her_Base 0.086463 0.003757 0.005099 0.000222
Her_All 0.086463 0.003757 0.005099 0.000222
#+end_quote

From the log:
#+begin_quote
Reading details for 4421450 predictors...

[...]

In total, 613226 predictors have ambiguous alleles

[...]

Warning, results/iga_meta/with_epic/with_liu/with_scepanovic/with_dennis/with_pietzner/without_gudjonsson/with_eldjarn/with_mhc/snps_only/procd.assoc contains (valid) summary statistics for only 3918240 of the 4421450 predictors
#+end_quote

I have modified the code used to produce the =assoc= file.

Ok, got it:

#+begin_quote
      chr      N
   <char>  <int>
1:      1 775449
2:      2 830726
3:      3 703194
4:      4 722857
5:      5 640607
6:      6 245407
#+end_quote

Maybe the =tmp= directory was full? Rerunning these jobs now.

**** Including IGH/K/L as annotations

#+begin_quote
Component Heritability Her_SD Influence Inf_SD
Her_P1 0.005954 0.000641 0.001655 0.000178
Her_P2 0.001351 -9999.000000 -0.000041 -304.042900
Her_P3 0.000013 0.000110 0.000000 0.000000
Her_P4 0.176995 0.005406 0.003981 0.000122
Her_All 0.184312 0.005052 0.005595 0.000204
#+end_quote

** Genetic correlation estimation
*** Does SumHer report the genetic covariance intercept?

What does =Overlap= mean?

** New Ig associations

*** Workflow

- OMIM for text
- OTG for PheWAS, candidate genes
- 

*** Candidate novel IgA hits
**** POU3F1

Very far away from POU3F1 TSS (~127kb), which seems to relate to development of the myelin sheath in mice.

No obvious relationship to POU2AF1.

Lead SNP is associated with a scattering of IMDs.

**** GOLPH3L, HORMAD1

This SNP is associated with a ton of white blood cell traits.

It is an intronic variant in GOLPH3L.

GOLPH3L is localised at Golgi stack, may have regulatory role in Golgi trafficking [[https://www.ncbi.nlm.nih.gov/gene/55204][GenBank]].

Overexpressed in some cancers.

HORMAD1 has some relationship with DSBs.

**** SCYL3 (rs3766151)

Intronic variant in SCYL3.

SNP is associated with E-selectin levels; E-selectin is a cell adhesion molecule mediating attachment of leukocytes to endothelial cells.

**** FAM98A,RASGRP3 (rs13388394)

SNP is a missense variant in RASGRP3, I've written up more in the paper draft. This is a good hit.

**** B3GNT2,COMMD1

Intergenic SNP.

COMMD1 has some relationship with NFKB regulation [[https://www.ncbi.nlm.nih.gov/gene/150684][GenBank]].

B3GNT2 encodes a poly-N-acetyllactosamine poly-LacNAc synthase.

[[https://www.nature.com/articles/s41467-022-29205-8][From]]:
#+begin_quote
In the immune system, B3GNT2 is upregulated in T cells upon activation and B3GNT2 knockout mice have lower poly-LacNAc on B and T cells, resulting in hyperactivity35,37. Single nucleotide polymorphisms that reduced expression of B3GNT2 have been associated with autoimmune diseases38,39,40.
#+end_quote

Other than being about ~48kb away from B3GNT2, there's not a good link between this SNP and B3GNT2.

**** EIF2AK3,RPIA

[[https://genetics.opentargets.org/Variant/2_88613755_G_C/associations][OTG]]

Missense variant in EIF2AK3

RPIA encodes ribose-5-phosphate isomerase A, part of pentose phosphate pathway.

Mutations in EIF2AK3 (encodes PERK protein) cause IDDM as part of Wolcott-Rallison syndrome.

This SNP is strongly associated with anthropometric traits like height and 'appendicular lean mass'.

Linked to RPIA with PCHi-C data.

eQTL for both genes in blood and brain.

Apparently EIF2AK3 is largely suppressed in plasma cells and does not play a role in the unfolded protein response [[https://pubmed.ncbi.nlm.nih.gov/19898960/][paper.]]

**** SP110,SP140 (rs62193147)

[[https://genetics.opentargets.org/Variant/2_230251645_T_C/associations][otg]]

Intronic variant in SP140, also an s-/eQTL for this gene.

SP140 is a 'nuclear body protein', 'SP' is 'speckled protein' [[https://www.cell.com/trends/immunology/fulltext/S1471-4906(20)30072-7][review]]

SNP's associated with a lot of blood cell traits, including 'lymphocyte percentage'-type traits.

Abundantly expressed in B cells and linked with [[https://academic.oup.com/hmg/article/27/23/4012/5068135?login=false][IMDs]]

**** TSEN2,MKRN2,RAF1 

[[https://genetics.opentargets.org/Variant/3_12461456_G_T/associations][OTG]]

MKRN2 encodes a E3 ubiquitin ligase which negatively regulates inflammatory responses, targets the p65 subunit of NF-kB [[https://www.nature.com/articles/srep46097][paper]].

RAF1 encodes a protein in the MAPK-ERK pathway, involved in B cell development/plasma cell development [[https://pubmed.ncbi.nlm.nih.gov/33975980/#:~:text=By%20analyzing%20mice%20with%20B,B%20cells%20to%20pre%2Dplasmablasts][paper]]

TSEN2 encodes a tRNA-splicing endonuclease, can't relate this easily to B cells.

No e-/sQTL evidence for this SNP in B cells.

**** ACTRT3

[[https://genetics.opentargets.org/Variant/3_169764547_T_C/associations][OTG]]

Non-coding transcript exon variant.

ACTRT3 encodes actin-related protein T3.

GPR160 hsa some role in prostate cancer.

SNP's associated with a lot of cancers and blood cell traits.

**** TBL1XR1 (rs55901664)

[[https://genetics.opentargets.org/Variant/3_177042914_A_T/associations][OTG]]

Intronic variant in TBL1XR1.

**** TP63

[[https://genetics.opentargets.org/Variant/3_189683987_G_C/associations][OTG]]

Intronic variant in TP63.


**** TLR1

[[https://genetics.opentargets.org/Variant/4_38809930_G_T/associations][OTG]]

Relatively rare SNP

Expressed in activated and memory B cells, TLR1/2 heterodimer senses bacterial lipoproteins [[https://pmc.ncbi.nlm.nih.gov/articles/PMC3401975/][paper]]

TLR11 does not produce a functional protein.

**** NFKB1

[[https://genetics.opentargets.org/Variant/4_102523541_C_T/associations][OTG]]

**** IL7R (rs6890853)

[[https://genetics.opentargets.org/Variant/5_35852209_G_A/associations][OTG]]

**** PTGER4 (rs10440635)

[[https://genetics.opentargets.org/Variant/5_40490688_G_A/associations][OTG]]


PTGER4 encodes the PGE2 prostaglandin E2 receptor.


**** HIVEP2

This is in moderate LD (r2 = ~0.65) with a SNP which came up in a multivariate analysis of IgG N-glycosylation phenotypes.

**** SNX13

[[https://genetics.opentargets.org/Variant/7_17685515_C_T/associations][OTG]]

Far away from SNX13, not much to say.

SNX13 is a GTPase activating protein, some role in vesicular trafficking.

**** POU5F1B

[[https://genetics.opentargets.org/Variant/8_127210176_T_C/associations][OTG]]

Gene may relate to prostate and colon cancer. SNP is ~113kb away from POU5F1B, though.

**** SYK

[[https://genetics.opentargets.org/Variant/9_90792925_C_T/associations][OTG]]

SYK is a non-receptor tyrosine kinase ('spleen-associated tyrosine kinase').

**** TRAF1 (rs113495277)

[[https://genetics.opentargets.org/Variant/9_120913617_A_G/associations][OTG]]

**** IFITM1,IFITM2
[[https://genetics.opentargets.org/Variant/11_308363_G_C/associations][OTG]]

This SNP has extremely significant associations with lots of blood cell traits.

IFITM1/2 are known as factors in cell-intrinsic antiviral immunity.

**** PTPRJ/MTCH2

[[https://genetics.opentargets.org/Variant/11_47947600_T_C/associations][OTG]]

MTCH2 participates in apoptosis so probably easy to relate this to B cells.

PTPRJ is CD148, a receptor-like PTP. CD148 is a 'Src-family

**** TRIM49B,FOLH1

FOLH1 encodes a folate hydrolase.

This SNP is an intronic variant in TRIM49B, thought to encode a ubiquitin ligase.

SNP is an eQTL for PTPRJ.

**** GRAMD1B (rs2714073)

The lead SNP for IgM is rs735665, which is associated with IgM, lymphocyte counts, CLL, and follicular lymphoma.

The anti-PC IgM lead SNP and rs735665 have r2 = ~1.

**** BCL2L14 (rs1008866)

[[https://genetics.opentargets.org/Variant/12_12022938_G_A/associations][OTG]]

BCL2 family member, aka BCLG.

Has some apoptic-related function but nothing I can find relating it to B cells specifically.

**** FBRSL1

[[https://genetics.opentargets.org/Variant/12_132469613_G_A/associations][OTG]]

Variants in FBRSL1 cause intellectual disability and malformation syndrome.

**** BMF

[[https://genetics.opentargets.org/Variant/15_40105735_G_T/associations][OTG]]



**** FRMD5,ADAL

**** MAF,WWOX

**** GSDMB

**** PHOSPHO1,GNGT2

**** CD79,FTSJ3

**** SLC25A19,GRB2

**** CBX4,TBC1D16

**** ZBTB7A

**** SLC35E1,C19orf44

**** CLASRP

**** MYBPC2,SPIB

**** RIMBP3C,UBE2L3

**** DERL3
*** TODO Candidate novel IgG hits

There are more hits which were not annotated by OTG.

**** AFF3
**** RPP14,PXK
**** HHEX
**** ZPBP2,GSDMB

*** Candidate novel IgM hits

**** LAPTM5

**** TARS2,ADAMTSL4

**** MTIF2,CLHC1

**** STK25,FARP2

**** SLC35G2

**** MBNL1

**** RHOH

**** STAP1,UBA6

**** unlabelled chr6:121,440,620

**** HIVEP2,HIVEP2

**** CARD11

IEI gene?

**** TRA2A,CCDC126

**** PRKAR2B,HBP1

**** BCAP29,HBP1

**** RPS20,LYN

**** PAX5,ZCCHC7

**** SYK

**** KLF6

**** DUSP5

**** TCIRG1

**** COLCA2,POU2AF1

**** NXPE1,REX02

**** RAB21

**** SLITRK6

**** BATF,NEK9

**** LGMN,RIN3

**** unlabelled chr15:50,492,793

**** CPLX3,ULK3

**** CIITA

**** PLCG2

**** IRF8

**** TNFRSF13B

**** BCL2

**** KLF2

**** COLGALT1,NIBAN3

**** KASH5,DKKL1

**** GRIK1

**** unlabelled chr22:50,704,843
** EPIC phenotypic correlations

#+begin_src
> cor(dat[, .SD, .SDcols = patterns('IG')], use = 'pairwise.complete.obs')
           IGA_CONC   IGG1_CONC   IGG2_CONC  IGG3_CONC    IGG4_CONC
IGA_CONC   1.000000000  0.16948769  0.22426911 0.17878454  0.174424557
IGG1_CONC  0.169487687  1.00000000 -0.06646444 0.02177384  0.086556574
IGG2_CONC  0.224269112 -0.06646444  1.00000000 0.16396403  0.229087348
IGG3_CONC  0.178784544  0.02177384  0.16396403 1.00000000  0.044582203
IGG4_CONC  0.174424557  0.08655657  0.22908735 0.04458220  1.000000000
IGM_CONC  -0.004271912  0.05946210  0.09329625 0.08815389 -0.006951686
IGG_CONC   0.300423384  0.82011455  0.44850020 0.23345022  0.414992445
              IGM_CONC   IGG_CONC
IGA_CONC  -0.004271912 0.30042338
IGG1_CONC  0.059462096 0.82011455
IGG2_CONC  0.093296247 0.44850020
IGG3_CONC  0.088153887 0.23345022
IGG4_CONC -0.006951686 0.41499245
IGM_CONC   1.000000000 0.09890761
IGG_CONC   0.098907611 1.00000000
#+end_src

i.e.

| First isotype | Second isotype |      r |
|---------------+----------------+--------|
| IgA           | IgG            |  0.300 |
| IgA           | IgM            | -0.004 |
| IgM           | IgG            |  0.099 |
| IgM           | IgG1           |  0.059 |
| IgM           | IgG2           |  0.093 |
| IgM           | IgG3           |  0.088 |
| IgM           | IgG4           | -0.007 |
| IgA           | IgG1           |  0.169 |
| IgA           | IgG2           |  0.224 |
| IgA           | IgG3           |  0.179 |
| IgA           | IgG4           |  0.174 |

Note that these are on the scale of the raw data. The GWAS was performed on log-transformed Ig concentrations:
#+begin_src
> dat[, cor(log(IGA_CONC), log(IGM_CONC), use = 'complete.obs')]
[1] 0.05032
> dat[, cor(log(IGG_CONC), log(IGM_CONC), use = 'complete.obs')]
[1] 0.1756809
> dat[, cor(log(IGG_CONC), log(IGA_CONC), use = 'complete.obs')]
[1] 0.3768878
#+end_src

If we log-transform them and standardise, naturally it makes no difference to the Pearson correlation.
#+begin_src
> dat[!is.na(IGM_CONC) & !is.na(IGA_CONC), cor(preproc(IGM_CONC), preproc(IGA_CONC), use = 'complete.obs')]
[1] 0.05032
> dat[!is.na(IGG_CONC) & !is.na(IGM_CONC), cor(preproc(IGG_CONC), preproc(IGM_CONC), use = 'complete.obs')]
[1] 0.1756809
> dat[!is.na(IGG_CONC) & !is.na(IGA_CONC), cor(preproc(IGG_CONC), preproc(IGA_CONC), use = 'complete.obs')]
[1] 0.3768878
#+end_src

*** Constraining the LDSC intercept for the EPIC data

**** IgG and IgA

***** LDSC

Without:
#+begin_src
Heritability of phenotype 1
---------------------------
Total Observed scale h2: 0.1909 (0.0564)
Lambda GC: 1.0285
Mean Chi^2: 1.0427
Intercept: 1.0072 (0.0046)
Ratio: 0.1686 (0.1067)

Heritability of phenotype 2/2
-----------------------------
Total Observed scale h2: 0.1438 (0.0658)
Lambda GC: 1.0135
Mean Chi^2: 1.0301
Intercept: 1.005 (0.0047)
Ratio: 0.1665 (0.1546)

Genetic Covariance
------------------
Total Observed scale gencov: 0.0605 (0.0304)
Mean z1*z2: 0.377
Intercept: 0.3669 (0.0027)

Genetic Correlation
-------------------
Genetic Correlation: 0.3653 (0.1356)
Z-score: 2.6947
P: 0.007


Summary of Genetic Correlation Results
p1                                          p2      rg      se       z      p  h2_obs  h2_obs_se  h2_int  h2_int_se  gcov_int  gcov_int_se
results/ldsc/epic-iga/epic-iga.sumstats.gz  results/ldsc/epic-igg/epic-igg.sumstats.gz  0.3653  0.1356  2.6947  0.007  0.1438     0.0658   1.005     0.0047    0.3669       0.0027

Analysis finished at Sun Feb  9 23:53:57 2025
Total time elapsed: 1.0m:22.64s
#+end_src

That's a pretty good estimate of the intercept!

With constrained intercept:

#+begin_src
Heritability of phenotype 1
---------------------------
Total Observed scale h2: 0.1909 (0.0564)
Lambda GC: 1.0285
Mean Chi^2: 1.0427
Intercept: 1.0072 (0.0046)
Ratio: 0.1686 (0.1067)

Heritability of phenotype 2/2
-----------------------------
Total Observed scale h2: 0.1438 (0.0658)
Lambda GC: 1.0135
Mean Chi^2: 1.0301
Intercept: 1.005 (0.0047)
Ratio: 0.1665 (0.1546)

Genetic Covariance
------------------
Total Observed scale gencov: -0.0012 (0.026)
Mean z1*z2: 0.377
Intercept: constrained to 0.377

Genetic Correlation
-------------------
Genetic Correlation: -0.007 (0.162)
Z-score: -0.0432
P: 0.9655
#+end_src

***** SumHer

#+begin_src
Component Value SD
Her1_All 0.418535 0.083220
Her2_All 0.239618 0.105015
Coher_All 0.104272 0.053953
Cor_All 0.329262 0.133811
Scaling1 1.002914 0.002977
Scaling2 1.005616 0.003566
Overlap 0.367195 0.001786
#+end_src

If =Overlap= is the intercept, it's pretty close to that estimated by LDSC.

**** IgG and IgM

***** LDSC
Without:
#+begin_quote
Heritability of phenotype 1
---------------------------
Total Observed scale h2: 0.3711 (0.0971)
Lambda GC: 1.0466
Mean Chi^2: 1.0702
Intercept: 0.9983 (0.0057)
Ratio < 0 (usually indicates GC correction).

Heritability of phenotype 2/2
-----------------------------
Total Observed scale h2: 0.1438 (0.0658)
Lambda GC: 1.0135
Mean Chi^2: 1.0301
Intercept: 1.005 (0.0047)
Ratio: 0.1666 (0.1546)

Genetic Covariance
------------------
Total Observed scale gencov: 0.032 (0.0306)
Mean z1*z2: 0.1825
Intercept: 0.1774 (0.0025)

Genetic Correlation
-------------------
Genetic Correlation: 0.1384 (0.1228)
Z-score: 1.1266
P: 0.2599
#+end_quote

With:

#+begin_quote
Heritability of phenotype 1
---------------------------
Total Observed scale h2: 0.3711 (0.0971)
Lambda GC: 1.0466
Mean Chi^2: 1.0702
Intercept: 0.9983 (0.0057)
Ratio < 0 (usually indicates GC correction).

Heritability of phenotype 2/2
-----------------------------
Total Observed scale h2: 0.1438 (0.0658)
Lambda GC: 1.0135
Mean Chi^2: 1.0301
Intercept: 1.005 (0.0047)
Ratio: 0.1666 (0.1546)

Genetic Covariance
------------------
Total Observed scale gencov: 0.043 (0.0263)
Mean z1*z2: 0.1825
Intercept: constrained to 0.1757

Genetic Correlation
-------------------
Genetic Correlation: 0.1861 (0.1098)
Z-score: 1.6948
P: 0.0901
#+end_quote

***** SumHer

#+begin_quote
Component Value SD
Her1_All 0.239702 0.105021
Her2_All 0.613568 0.147122
Coher_All 0.066774 0.057580
Cor_All 0.174116 0.139211
Scaling1 1.005611 0.003566
Scaling2 1.001453 0.004103
Overlap 0.176587 0.002023
#+end_quote

**** IgA and IgM
***** LDSC
Without:

#+begin_src
Heritability of phenotype 1
---------------------------
Total Observed scale h2: 0.1909 (0.0564)
Lambda GC: 1.0285
Mean Chi^2: 1.0427
Intercept: 1.0072 (0.0046)
Ratio: 0.1686 (0.1067)

Heritability of phenotype 2/2
-----------------------------
Total Observed scale h2: 0.3711 (0.0971)
Lambda GC: 1.0466
Mean Chi^2: 1.0702
Intercept: 0.9983 (0.0057)
Ratio < 0 (usually indicates GC correction).

Genetic Covariance
------------------
Total Observed scale gencov: 0.0007 (0.0356)
Mean z1*z2: 0.0845
Intercept: 0.084 (0.0026)

Genetic Correlation
-------------------
Genetic Correlation: 0.0026 (0.1473)
Z-score: 0.0178
P: 0.9858
#+end_src

With:

#+begin_src 
Heritability of phenotype 1
---------------------------
Total Observed scale h2: 0.1909 (0.0564)
Lambda GC: 1.0285
Mean Chi^2: 1.0427
Intercept: 1.0072 (0.0046)
Ratio: 0.1686 (0.1067)

Heritability of phenotype 2/2
-----------------------------
Total Observed scale h2: 0.3711 (0.0971)
Lambda GC: 1.0466
Mean Chi^2: 1.0702
Intercept: 0.9983 (0.0057)
Ratio < 0 (usually indicates GC correction).

Genetic Covariance
------------------
Total Observed scale gencov: 0.2177 (0.0275)
Mean z1*z2: 0.0845
Intercept: constrained to 0.0503

Genetic Correlation
-------------------
Genetic Correlation: 0.818 (0.224)
Z-score: 3.6519
P: 0.0003
#+end_src

***** SumHer

#+begin_quote
Component Value SD
Her1_All 0.419135 0.083249
Her2_All 0.614008 0.146983
Coher_All 0.010734 0.063136
Cor_All 0.021158 0.129049
Scaling1 1.003017 0.002967
Scaling2 1.001453 0.004103
Overlap 0.083595 0.002010
#+end_quote
** Effect allele frequencies

Not able to fetch all EAFs from gnomAD r4. Can I use the =effect_allele_frequency= columns from the contributing studies?

Would need to check that these columns are concordant with the gnomAD reports.

What about the =AF1.dennis= and =ImpMAF.eldjarn= columns (latter in particular is quite comprehensive)?

=ImpMAF.eldjarn= doesn't always give the effect allele; it's labelled 'MAF' after all. E.g. with the IgA lead SNPs:

#+begin_src
> dat[!is.na(EAF)][effect_allele_frequency.scepanovic > 0.5][1, .SD, .SDcols = patterns('rsid|EAF|freq|ImpMAF|AF1')]
        rsid       EAF effect_allele_frequency.epic
      <char>     <num>                        <num>
1: rs3766151 0.6803925                     0.326583
   effect_allele_frequency.pietzner effect_allele_frequency.scepanovic
                              <num>                              <num>
1:                           0.6645                           0.678068
   AF1.dennis ImpMAF.eldjarn
        <num>          <num>
1:   0.316375        0.32104
#+end_src

Also note how the EPIC frequency looks to be wrongly specified and does not agree with EAF!

When I do try to coalesce these in the absence of =EAF= from gnomAD, I will need to check that all columns are consistently >/< 0.5.

*** Harmonising the 'sign'

Need to make sure that I am dealing with the effect allele frequency when considering all of the columns.

E.g. AF1.dennis was > 0.5 for one SNP in the IgA meta-analysis, so close to being the MAF but not quite. Of three datasets for which I had =effect_allele_frequency= estimates, two were >0.5. ImpMAF.eldjarn was <0.5 for all (as per the name).

*** Pooling EAF estimates?

Could we weight estimates by sample size and get a pooled estimate from a 'meta-analysis' of MAF estimates? The problem is that we don't get genotype calls for every individual in the sample.

**** Datasets

***** IgA

We have

**** Method

#+begin_ai
I have a data.table with columns corresponding to MAF estimates. These columns contain NA values. I want to compute sample size-weighted meta-analytic MAF estimates using these columns.


[AI]: Below is one way to do this in R using data.table. The idea is to compute a weighted average for each row where the weights are the sample sizes, so that the metaâanalytic MAF is

ââmeta_MAF = (ââ nâ Ã MAFâ) / (ââ nâ)

In the example below, we assume your table (called dt) has, for example, three MAF columns (e.g., MAF_1, MAF_2, MAF_3) and corresponding sample size columns (e.g., N_1, N_2, N_3). We then use rowSums (with na.rm=TRUE) to âskip overâ any NA values in the weighted average calculation. (Be cautious: if a particular row has NA for all sample sizes, the denominator will be 0 and you might want to handle that case.)

Hereâs some example code:

-------------------------------------------------
library(data.table)

# Example data
dt <- data.table(
  MAF_1 = c(0.10, NA, 0.15, 0.20),
  MAF_2 = c(0.12, 0.14, NA, 0.18),
  MAF_3 = c(NA, 0.13, 0.16, 0.19),
  N_1   = c(100, 150, 120, 130),
  N_2   = c(200, 220, 180, 210),
  N_3   = c(150, 160, 140, 190)
)

# Compute the meta-analytic MAF as sample size-weighted average across the MAF columns.
# The formula is: meta_MAF = (MAF_1*N_1 + MAF_2*N_2 + MAF_3*N_3) / (N_1+N_2+N_3)
# We want to remove NA values â meaning if a particular MAF is missing, we ignore its sample size as well.

dt[, meta_MAF := {
  # Compute weighted contributions; NA values in multiplication will yield NA so we use cbind() with na.rm
  # For each row, the weighted sum is:
  numer <- rowSums(cbind(MAF_1 * N_1, MAF_2 * N_2, MAF_3 * N_3), na.rm = TRUE)
  # And the total weight is the sum of sample sizes, but only for non-NA MAF estimates.
  denom <- rowSums(cbind(ifelse(is.na(MAF_1), 0, N_1),
                         ifelse(is.na(MAF_2), 0, N_2),
                         ifelse(is.na(MAF_3), 0, N_3)),
                    na.rm = TRUE)
  # Avoid division by zero:
  out <- ifelse(denom > 0, numer/denom, NA_real_)
  out
}]

print(dt)
-------------------------------------------------

Explanation:
1. We create a weighted sum in the numerator. Multiplying MAF_i * N_i results in NA if MAF_i is NA. Using rowSums with na.rm = TRUE ignores those NA contributions.
2. For the denominator, we only want to add the sample size N_i if the corresponding MAF_i is not NA. We use ifelse(is.na(MAF_i), 0, N_i) to achieve that.
3. The meta_MAF is then the weighted sum divided by the total sample size for which we had a MAF estimate.
4. We use an ifelse to return NA in cases where no valid MAFs are available (denom is 0).

This approach easily scales for more than three columns. Just adjust the column names (or use patterns / .SDcols if they follow a naming convention).

Alternate Approach Using .SD:
If your column names have a clear pattern, you can take advantage of .SD. For example:

-------------------------------------------------
# Suppose your MAF columns all start with "MAF" and sample size columns with "N".
mafcols <- grep("^MAF", names(dt), value = TRUE)
ncols   <- grep("^N",   names(dt), value = TRUE)

dt[, meta_MAF := {
  numer <- rowSums(mapply(function(maf, n){
    # For each pair, replace MAF NA with 0 so it doesn't contribute.
    ifelse(is.na(maf), 0, maf * n)
  }, .SD[[mafcols]], .SD[[ncols]]), na.rm=TRUE)
  
  denom <- rowSums(mapply(function(maf, n){
    ifelse(is.na(maf), 0, n)
  }, .SD[[mafcols]], .SD[[ncols]]), na.rm=TRUE)
  
  ifelse(denom > 0, numer/denom, NA_real_)
}, .SDcols = c(mafcols, ncols)]
-------------------------------------------------

Choose the approach that best fits your data setup. This method correctly handles NA values and yields the sample sizeâweighted meta-analytic MAF estimate for each row.

[ME]: What if I have the sample sizes in a separate vector?

[AI]: Assume you have a data.table with several MAF columns (which may contain NA values) and that your sample sizes for these columns are stored in a separate vector. For example, suppose your data.table (named dt) looks like this:

  MAF_1   MAF_2   MAF_3
1  0.10    0.12     NA
2   NA     0.14    0.13
3  0.15     NA     0.16
4  0.20    0.18    0.19

and your sample sizes vector is defined as

  sample_sizes = c(100, 200, 150)

That is, the weight for MAF_1 is 100, for MAF_2 is 200, and for MAF_3 is 150. The desired meta-analytic MAF estimate for each row is computed as:

ââmeta_MAF = (MAF_1*100 + MAF_2*200 + MAF_3*150) / (sum of sample sizes for nonâmissing MAF values)

Below are two ways to do this in R. Both methods construct a weighted average for each row by zeroing out weights corresponding to NA MAF estimates.

ââââââââââââââââââââââââââ
Method 1: Using Matrix Operations

In this example we convert the relevant MAF columns into a matrix, compute the numerator and denominator rowâwise, and properly handle the NA values:

-------------------------------------------------
library(data.table)

# Example data.table with MAF columns
dt <- data.table(
  MAF_1 = c(0.10, NA, 0.15, 0.20),
  MAF_2 = c(0.12, 0.14, NA, 0.18),
  MAF_3 = c(NA, 0.13, 0.16, 0.19)
)

# Sample sizes vector corresponding to the MAF columns
sample_sizes <- c(100, 200, 150)

# Calculate meta-analytic MAF weighted by sample sizes
dt[, meta_MAF := {
  # Create matrix from the selected MAF columns
  maf_mat <- as.matrix(.SD)
  
  # Multiply each element by its corresponding sample size.
  # Here we replicate the sample_sizes vector by row.
  weight_mat <- matrix(sample_sizes, nrow(maf_mat), length(sample_sizes), byrow = TRUE)
  
  # For NA values, set the effective weight to 0.
  effective_weights <- ifelse(is.na(maf_mat), 0, weight_mat)
  
  # Compute the weighted sum for each row.
  numerator <- rowSums(ifelse(is.na(maf_mat), 0, maf_mat) * weight_mat)
  
  # Compute the total weight for each row (only counting non-NA MAF estimates).
  denominator <- rowSums(effective_weights)
  
  # Return the weighted average; if no weights present (denom==0), return NA.
  ifelse(denominator > 0, numerator / denominator, NA_real_)
}, .SDcols = c("MAF_1", "MAF_2", "MAF_3")]

print(dt)
-------------------------------------------------

ââââââââââââââââââââââââââ
Method 2: Using apply() Over Rows

This approach processes each row separately. The function checks whether a given MAF value is missing; if it is, its corresponding weight is set to zero. Then it computes the weighted mean for that row.

-------------------------------------------------
dt[, meta_MAF := apply(.SD, 1, function(maf_row) {
  # Use the provided sample_sizes vector.
  # Create a weight vector where NA MAF's get a weight of zero.
  effective_weights <- ifelse(is.na(maf_row), 0, sample_sizes)
  
  # Calculate the weighted average.
  if(sum(effective_weights) > 0) {
    sum(maf_row * sample_sizes, na.rm = TRUE) / sum(effective_weights)
  } else {
    NA_real_
  }
}), .SDcols = c("MAF_1", "MAF_2", "MAF_3")]

print(dt)
-------------------------------------------------

ââââââââââââââââââââââââââ
Explanation

â¢ For each row the numerator is calculated as the sum of (MAF Ã corresponding sample size). If a MAF value is NA, its contribution is zero.
â¢ The denominator is the sum of the sample sizes for positions where the MAF value is not missing.
â¢ Finally, the meta-analytic MAF is computed as the numerator divided by the denominator (or NA if no valid data exist).

Choose whichever method best fits your coding style or performance needs. Both methods correctly account for NA values by âdropping outâ the sample size associated with any missing MAF estimate.

[ME]: 
#+end_ai

** Paper by the numbers
*** Sample sizes
- IgA: 85,204
- IgG: 58,777
- IgM: 55,368
*** No. of associations
- IgA: 106
- IgG: 19
- IgM: 89
**** Novel associations
- IgA: 40
- IgG: 9
- IgM: 37
**** TODO Number of known associations prior to this study
** DONE Slow =distance_clump= <2025-03-10 Mon>

#+begin_org-ai
Can you optimise the following R code? It uses data.table.
dat <- fread(snakemake@input[[1]], sep = '\t', select = c(chr_col, bp_col, ref_col, alt_col, rsid_col, p_col, beta_col, se_col))

if(!snakemake@params$mhc) {
  dat <- dat[!(get(chr_col) == 6 & get(bp_col) %between% c(24e6, 45e6))]
}

dat[, (chr_col) := as.character(get(chr_col))]
dat[, (bp_col) := as.integer(get(bp_col))]

#dat <- dat[!(get(snp_col) %in% snakemake@params$snps_to_ignore)]

dat <- dat[get(p_col) <= index_threshold]

dat <- dat[order(get(p_col))]

for(i in unique(dat[[chr_col]])) {
  j <- 1

  while(j <= dat[get(chr_col) == i, .N]) {
    bp <- dat[get(chr_col) == i][j][[bp_col]]

    dat <- dat[!(get(chr_col) == i & get(bp_col) != bp & get(bp_col) %between% c(bp-distance_window/2, bp+distance_window/2))]

    j <- j + 1
  }
}

dat <- dat[order(get(chr_col), get(bp_col))]

fwrite(dat, file = snakemake@output[[1]], sep = '\t')

[AI]: Here's an optimized and vectorized version of your code:

```r
library(data.table)

# Read file into a data.table
dat <- fread(snakemake@input[[1]], sep = '\t', select = c(chr_col, bp_col, ref_col, alt_col, rsid_col, p_col, beta_col, se_col))

# Remove rows if conditions hold
if (!snakemake@params$mhc) {
  dat <- dat[!(chr_col == 6 & bp_col %between% c(24e6, 45e6))]
} # Convert desired columns to specific types dat[, c(chr_col, bp_col) := .(as.character(chr_col), as.integer(bp_col))]

# Filter out rows based on column values
dat <- dat[p_col <= index_threshold]

# Order rows based on column values
setorder(dat, p_col)

dat <- dat[, !ranges := data.table::frankv(bp_col, ties.method = "dense")]

median_bp <- median(bp_col)
dat[, !rows_to_remove := abs(bp_col - median_bp) > distance_window/2]
dat <- dat[!(rows_to_remove == TRUE),]

# Order rows based on column values
setorder(dat, chr_col, bp_col)

# Write updated data.table to a file
fwrite(dat, file = snakemake@output[[1]], sep = '\t')
```

This optimized version of the code accomplishes the same tasks as the original while providing several enhancements:

1. The code uses direct reference to the column names instead of the `get()` function. You should notice a performance boost as a result, especially for larger data.

2. The nested loop to remove rows has been replaced. While loops can be slower in R, this vectorized solution should also improve performance. 

3. The code removes a redundant ordering operation (`setorder`) by ordering the data only once after all filtering operations have been performed.

4. It simplifies your conditions to make your code cleaner as well as potentially faster.

5. It adds measures to use `data.table`'s fast grouping and sorting capabilities, which is specially designed for large datasets.

Overall, the optimization should make the code faster and easier to read and maintain.

#+end_org-ai


I don't think o3-mini got this right and the problem in any case was that the =p_value= column was identified as a =character= column.
** Mendelian randomisation <2025-03-11 Tue>
*** Ig and lymphocyte counts
**** Ig variants as instruments

Penalty is intended to account for heterogeneous (i.e. outlying) 'variant-specific estimates' as per the package docs.

IgA only has a significant slope for 'penalized weighted median' and it's negative!

IgM has significant estimates for quite a few methods but the sign and magnitude of the estimates are all over the place.

IgG also has many significant estimates, all positive, a couple of non-significant negative estimates.

***** IgA
#+begin_quote
Method	Estimate	Std Error	95% CI 	 	P-value
Simple median	-0.292064393989576	1.02754215266547	-2.30601000581065	1.7218812178315	0.776229586316705
Weighted median	-0.0980488058570843	0.0913206241374101	-0.277033940212127	0.0809363284979587	0.282967708481664
Penalized weighted median	-1.27016375861641	0.239104810849575	-1.73880057641184	-0.801526940820985	1.08331564326494e-07
IVW	-0.1881572616759	0.382821856682402	-0.938474313268161	0.562159789916362	0.623072262668913
Penalized IVW	-1.26592488783181	5.66157926594536	-12.3624163447034	9.83056656903982	0.823069145911547
Robust IVW	-0.0965570025077066	0.365299328081112	-0.812530529123367	0.619416524107954	0.791531063749147
Penalized robust IVW	4.51737658865183	365.35937530395	-711.573840421143	720.608593598447	0.990135046624313
MR-Egger	-0.122307819343941	0.525132877013255	-1.15154934538782	0.906933706699941	0.815832592965151
(intercept)	-0.00159329081857271	0.00863110486620945	-0.0185099455031316	0.0153233638659862	0.853543798334486
Penalized MR-Egger	-0.291351956132472	34.0133401179445	-66.9562735812151	66.3735696689501	0.99316555257444
(intercept)	-0.0287278795017248	0.651226776416716	-1.30510890704661	1.24765314804316	0.964813947606332
Robust MR-Egger	0.0017187864826584	0.488444660548349	-0.955615156632997	0.959052729598314	0.99719233215478
(intercept)	-0.00239763149004518	0.00814582019106475	-0.0183631456890713	0.0135678827089809	0.768498975368123
Penalized robust MR-Egger	0.0942327922857483	2703.35308313857	-5298.38044765463	5298.5689132392	0.999972187543484
(intercept)	0.0309013102803779	13.1667286438924	-25.7754126259607	25.8372152465214	0.998127427365292
#+end_quote

***** IgM
#+begin_quote
Method	Estimate	Std Error	95% CI 	 	P-value
Simple median	-3.34015790060455	1.05222034448571	-5.40247187959686	-1.27784392161223	0.00150151712255519
Weighted median	0.825649575810365	0.266578438796665	0.303165436713987	1.34813371490674	0.00195351012385157
Penalized weighted median	0.735448240003086	0.356246024683081	0.0372188619886812	1.43367761801749	0.0389760978366902
IVW	0.498710868412086	0.439805317008841	-0.363291713134464	1.36071344995864	0.256821598574481
Penalized IVW	-4.11999943233784	0.169503376985081	-4.45221994648651	-3.78777891818916	1.68171071954369e-130
Robust IVW	0.511947836055821	0.34397429613672	-0.162229395979665	1.18612506809131	0.136663448807116
Penalized robust IVW	-15.6397231431124	2.02878926149754	-19.6160770278692	-11.6633692583556	1.2691189627104e-14
MR-Egger	1.12243133197234	0.584464933229058	-0.0230988873832241	2.2679615513279	0.0548020221528087
(intercept)	-0.0149065441177159	0.00931657547777612	-0.0331666965134062	0.00335360827797432	0.109598027323663
Penalized MR-Egger	1.04970448429729	0.300105601849476	0.461508313113603	1.63790065548098	0.000469141439228382
(intercept)	-0.0238603806136729	0.0218010005995588	-0.0665895566157442	0.0188687953883984	0.27375212530677
Robust MR-Egger	1.14670731822549	0.410139197831176	0.342849261828234	1.95056537462274	0.00517557494763765
(intercept)	-0.016128356774393	0.0105704982055032	-0.0368461525558247	0.00458943900703861	0.127062258713992
Penalized robust MR-Egger	-1.01915552314282	91.8997649373893	-181.139384988123	179.101073941837	0.991151753326959
(intercept)	-0.0481736569465471	0.111770045775175	-0.267238921216283	0.170891607323189	0.666463379400734
#+end_quote

***** IgG
#+begin_quote
Method	Estimate	Std Error	95% CI 	 	P-value
Simple median	5.63406968944305	3.46959759298169	-1.16621663364792	12.434356012534	0.104410063162765
Weighted median	0.73788689696536	0.262852770660672	0.222704933233877	1.25306886069684	0.00499703089600192
Penalized weighted median	2.58604904284121	0.378864896354241	1.84348749098039	3.32861059470202	8.74478752236686e-12
IVW	0.97435698644189	1.25793640323428	-1.49115305873914	3.43986703162292	0.438595112109611
Penalized IVW	5.65472086147145	0.437253210100625	4.7977203175497	6.5117214053932	2.95560284428802e-38
Robust IVW	1.01165371608812	1.7443761764979	-2.40726076533744	4.43056819751368	0.561947272147809
Penalized robust IVW	15.015900933128	0.0545733522403012	14.9089391282214	15.1228627380346	0
MR-Egger	-0.869263863519347	2.01496943991424	-4.81853139570011	3.08000366866141	0.6661753681487
(intercept)	0.0348099362210029	0.0299864496937379	-0.0239624252029456	0.0935822976449514	0.245700652420514
Penalized MR-Egger	2.14819833522738	5.95465715737566	-9.52271523351256	13.8191119039673	0.718279341934751
(intercept)	0.0349013720596397	0.0105159992308394	0.0142903923057435	0.0555123518135359	0.000903782580283119
Robust MR-Egger	-0.949850503978567	1.98190934234803	-4.83432143560418	2.93462042764704	0.631753447557911
(intercept)	0.0371216636774121	0.0216196829472359	-0.00525213625634494	0.0794954636111692	0.0859735262168735
Penalized robust MR-Egger	13.9034818541937	1.07154020532637	11.8033016437674	16.00366206462	0
(intercept)	0.00559001430322851	0.00257302020754335	0.000546987364949762	0.0106330412415072	0.0298142244842223
#+end_quote

**** Lymphocyte counts variants as instruments

***** How many lead SNPs/discrete signals?

| Window (Mb) | No. of lead SNPs |
|-------------+------------------|
|           1 |              782 |
|           2 |              587 |
|           3 |              509 |

****** 1000kb

******* IgM
#+begin_quote
                       Method Estimate Std Error  95% CI       V5 P-value
                       <char>    <num>     <num>   <num>    <num>   <num>
 1:             Simple median  -0.0380   0.02200 -0.0810  5.5e-03 0.08700
 2:           Weighted median  -0.0082   0.02500 -0.0560  4.0e-02 0.74000
 3: Penalized weighted median  -0.0280   0.02400 -0.0760  2.0e-02 0.25000
 4:                       IVW   0.0130   0.02400 -0.0340  6.1e-02 0.58000
 5:             Penalized IVW  -0.0510   0.01500 -0.0810 -2.1e-02 0.00076
 6:                Robust IVW  -0.0360   0.02000 -0.0750  3.6e-03 0.07500
 7:      Penalized robust IVW  -0.0510   0.01600 -0.0820 -2.0e-02 0.00120
 8:                  MR-Egger   0.0900   0.05000 -0.0070  1.9e-01 0.06900
 9:               (intercept)  -0.0019   0.00110 -0.0041  2.1e-04 0.07700
10:        Penalized MR-Egger   0.0410   0.03100 -0.0200  1.0e-01 0.19000
11:               (intercept)  -0.0019   0.00068 -0.0032 -5.6e-04 0.00540
12:           Robust MR-Egger   0.0310   0.03900 -0.0450  1.1e-01 0.43000
13:               (intercept)  -0.0017   0.00081 -0.0032 -7.2e-05 0.04000
14: Penalized robust MR-Egger   0.0350   0.03100 -0.0250  9.6e-02 0.25000
15:               (intercept)  -0.0019   0.00069 -0.0032 -5.3e-04 0.00620
#+end_quote

#+begin_quote
r$> dat[`P-value` < 0.05]
                 Method     Estimate    Std Error       95% CI            V5      P-value
                 <char>        <num>        <num>        <num>         <num>        <num>
1:        Penalized IVW -0.051099495 0.0151703206 -0.080832777 -2.136621e-02 0.0007560966
2: Penalized robust IVW -0.051376365 0.0158371907 -0.082416688 -2.033604e-02 0.0011785020
3:          (intercept) -0.001885270 0.0006781865 -0.003214491 -5.560486e-04 0.0054380813
4:          (intercept) -0.001659810 0.0008100085 -0.003247398 -7.222251e-05 0.0404497330
5:          (intercept) -0.001877946 0.0006854810 -0.003221464 -5.344276e-04 0.0061513496
#+end_quote

******* IgA

#+begin_quote
                       Method Estimate Std Error  95% CI      V5 P-value
                       <char>    <num>     <num>   <num>   <num>   <num>
 1:             Simple median  0.05600   0.02000  0.0180 0.09500 4.0e-03
 2:           Weighted median  0.08900   0.02100  0.0480 0.13000 1.9e-05
 3: Penalized weighted median  0.03600   0.02100 -0.0049 0.07600 8.5e-02
 4:                       IVW  0.08700   0.01900  0.0490 0.12000 8.6e-06
 5:             Penalized IVW  0.06300   0.01400  0.0360 0.08900 3.7e-06
 6:                Robust IVW  0.08400   0.02100  0.0430 0.13000 6.5e-05
 7:      Penalized robust IVW  0.06200   0.01500  0.0330 0.09200 3.8e-05
 8:                  MR-Egger  0.14000   0.04100  0.0570 0.22000 8.0e-04
 9:               (intercept) -0.00130   0.00090 -0.0030 0.00050 1.6e-01
10:        Penalized MR-Egger  0.10000   0.02900  0.0450 0.16000 4.9e-04
11:               (intercept) -0.00058   0.00061 -0.0018 0.00062 3.4e-01
12:           Robust MR-Egger  0.09500   0.05100 -0.0054 0.20000 6.4e-02
13:               (intercept) -0.00025   0.00093 -0.0021 0.00160 7.9e-01
14: Penalized robust MR-Egger  0.09300   0.03700  0.0210 0.17000 1.2e-02
15:               (intercept) -0.00043   0.00073 -0.0019 0.00100 5.5e-01
#+end_quote

#+begin_quote
r$> dat[`P-value` < 0.05]
                      Method   Estimate  Std Error     95% CI         V5      P-value
                      <char>      <num>      <num>      <num>      <num>        <num>
1:             Simple median 0.05631537 0.01956148 0.01797557 0.09465518 3.990767e-03
2:           Weighted median 0.08903488 0.02079334 0.04828069 0.12978908 1.853084e-05
3:                       IVW 0.08673600 0.01948868 0.04853889 0.12493312 8.563736e-06
4:             Penalized IVW 0.06280727 0.01357837 0.03619416 0.08942039 3.736271e-06
5:                Robust IVW 0.08443516 0.02113811 0.04300524 0.12586509 6.484395e-05
6:      Penalized robust IVW 0.06238698 0.01513828 0.03271649 0.09205747 3.770033e-05
7:                  MR-Egger 0.13678992 0.04078692 0.05684902 0.21673081 7.971888e-04
8:        Penalized MR-Egger 0.10191782 0.02922567 0.04463657 0.15919908 4.879767e-04
9: Penalized robust MR-Egger 0.09298107 0.03689118 0.02067569 0.16528645 1.172166e-02
#+end_quote

******* IgG

#+begin_quote
                       Method Estimate Std Error  95% CI      V5 P-value
                       <char>    <num>     <num>   <num>   <num>   <num>
 1:             Simple median  0.03500   0.02000 -0.0048 0.07500  0.0840
 2:           Weighted median  0.03600   0.02300 -0.0086 0.08100  0.1100
 3: Penalized weighted median  0.03600   0.02300 -0.0086 0.08100  0.1100
 4:                       IVW  0.03900   0.01500  0.0097 0.06800  0.0089
 5:             Penalized IVW  0.04200   0.01300  0.0160 0.06800  0.0018
 6:                Robust IVW  0.04200   0.01500  0.0120 0.07300  0.0061
 7:      Penalized robust IVW  0.04300   0.01400  0.0150 0.07200  0.0027
 8:                  MR-Egger  0.06200   0.03000  0.0022 0.12000  0.0420
 9:               (intercept) -0.00058   0.00068 -0.0019 0.00074  0.3900
10:        Penalized MR-Egger  0.07400   0.02700  0.0210 0.13000  0.0063
11:               (intercept) -0.00079   0.00060 -0.0020 0.00038  0.1900
12:           Robust MR-Egger  0.07100   0.03000  0.0120 0.13000  0.0190
13:               (intercept) -0.00072   0.00063 -0.0020 0.00051  0.2500
14: Penalized robust MR-Egger  0.07600   0.02900  0.0200 0.13000  0.0078
15:               (intercept) -0.00081   0.00060 -0.0020 0.00037  0.1800
#+end_quote

All IVW estimates were significant.

#+begin_quote
r$> dat[`P-value` < 0.05]
                      Method Estimate Std Error 95% CI    V5 P-value
                      <char>    <num>     <num>  <num> <num>   <num>
1:                       IVW    0.039     0.015 0.0097 0.068  0.0089
2:             Penalized IVW    0.042     0.013 0.0160 0.068  0.0018
3:                Robust IVW    0.042     0.015 0.0120 0.073  0.0061
4:      Penalized robust IVW    0.043     0.014 0.0150 0.072  0.0027
5:                  MR-Egger    0.062     0.030 0.0022 0.120  0.0420
6:        Penalized MR-Egger    0.074     0.027 0.0210 0.130  0.0063
7:           Robust MR-Egger    0.071     0.030 0.0120 0.130  0.0190
8: Penalized robust MR-Egger    0.076     0.029 0.0200 0.130  0.0078
#+end_quote

****** 2000kb

******* IgA

#+begin_quote
r$> iga
                       Method Estimate Std Error  95% CI      V5 P-value
                       <char>    <num>     <num>   <num>   <num>   <num>
 1:             Simple median  5.4e-02   0.02200  0.0120 0.09700 1.2e-02
 2:           Weighted median  9.3e-02   0.02300  0.0480 0.14000 4.1e-05
 3: Penalized weighted median  4.2e-02   0.02300 -0.0020 0.08700 6.1e-02
 4:                       IVW  9.1e-02   0.02100  0.0490 0.13000 2.1e-05
 5:             Penalized IVW  5.8e-02   0.01500  0.0290 0.08800 1.0e-04
 6:                Robust IVW  7.9e-02   0.02300  0.0330 0.12000 7.1e-04
 7:      Penalized robust IVW  5.8e-02   0.01700  0.0250 0.09100 5.4e-04
 8:                  MR-Egger  1.3e-01   0.04400  0.0450 0.22000 3.0e-03
 9:               (intercept) -1.1e-03   0.00100 -0.0031 0.00093 3.0e-01
10:        Penalized MR-Egger  9.7e-02   0.03200  0.0350 0.16000 2.3e-03
11:               (intercept) -5.8e-04   0.00069 -0.0019 0.00078 4.0e-01
12:           Robust MR-Egger  8.1e-02   0.05500 -0.0260 0.19000 1.4e-01
13:               (intercept) -4.7e-05   0.00100 -0.0021 0.00200 9.6e-01
14: Penalized robust MR-Egger  9.1e-02   0.03900  0.0140 0.17000 2.0e-02
15:               (intercept) -5.2e-04   0.00082 -0.0021 0.00110 5.3e-01
#+end_quote

******* IgG

#+begin_quote
r$> dat
                       Method Estimate Std Error   95% CI      V5 P-value
                       <char>    <num>     <num>    <num>   <num>   <num>
 1:             Simple median  0.01800   0.02300 -0.02600 0.06300   0.420
 2:           Weighted median  0.03600   0.02600 -0.01400 0.08600   0.160
 3: Penalized weighted median  0.03600   0.02600 -0.01400 0.08600   0.160
 4:                       IVW  0.03100   0.01700 -0.00160 0.06400   0.062
 5:             Penalized IVW  0.02700   0.01500 -0.00190 0.05700   0.067
 6:                Robust IVW  0.03300   0.01700 -0.00080 0.06700   0.056
 7:      Penalized robust IVW  0.03100   0.01600 -0.00033 0.06200   0.053
 8:                  MR-Egger  0.05400   0.03400 -0.01200 0.12000   0.110
 9:               (intercept) -0.00061   0.00078 -0.00210 0.00092   0.440
10:        Penalized MR-Egger  0.05500   0.03000 -0.00400 0.11000   0.068
11:               (intercept) -0.00061   0.00069 -0.00200 0.00075   0.380
12:           Robust MR-Egger  0.05800   0.03400 -0.00790 0.12000   0.084
13:               (intercept) -0.00066   0.00073 -0.00210 0.00078   0.370
14: Penalized robust MR-Egger  0.05900   0.03000  0.00067 0.12000   0.047
15:               (intercept) -0.00067   0.00068 -0.00200 0.00065   0.320
#+end_quote

****** 3000kb

Reran this with 3Mb clumping windows for fear of counting some signals many times over, no time to check almost 800 loci.

IVW convincing for IgA, marginal for IgG, unconvincing for IgM.

Estimate signs are mixed for IgM, too, whereas they are concordant across methods for IgA and for IgG, too.

I haven't looked at enough of these plots to judge, but there are also a lot of SNPs looking quite null around the origin.

There's maybe an argument for some penalty given the outlying variant effect estimates in each plot.

We know these are associated with the exposure, but not the outcome.

******* IgA

#+begin_quote
r$> iga
                       Method Estimate Std Error  95% CI     V5 P-value
                       <char>    <num>     <num>   <num>  <num>   <num>
 1:             Simple median  6.9e-02   0.02200  0.0250 0.1100 2.1e-03
 2:           Weighted median  6.8e-02   0.02300  0.0230 0.1100 3.4e-03
 3: Penalized weighted median  3.5e-02   0.02300 -0.0110 0.0800 1.4e-01
 4:                       IVW  8.0e-02   0.02300  0.0350 0.1300 5.2e-04
 5:             Penalized IVW  6.8e-02   0.01600  0.0370 0.0980 1.2e-05
 6:                Robust IVW  7.9e-02   0.02300  0.0340 0.1300 6.2e-04
 7:      Penalized robust IVW  6.7e-02   0.01800  0.0330 0.1000 1.5e-04
 8:                  MR-Egger  8.3e-02   0.04800 -0.0120 0.1800 8.7e-02
 9:               (intercept) -6.6e-05   0.00110 -0.0023 0.0022 9.5e-01
10:        Penalized MR-Egger  6.8e-02   0.03300  0.0027 0.1300 4.1e-02
11:               (intercept)  1.6e-04   0.00075 -0.0013 0.0016 8.3e-01
12:           Robust MR-Egger  4.2e-02   0.05300 -0.0630 0.1500 4.3e-01
13:               (intercept)  9.4e-04   0.00110 -0.0012 0.0030 3.8e-01
14: Penalized robust MR-Egger  5.8e-02   0.04300 -0.0260 0.1400 1.8e-01
15:               (intercept)  3.3e-04   0.00092 -0.0015 0.0021 7.2e-01
#+end_quote

******* IgM

#+begin_quote
r$> igm
                       Method Estimate Std Error  95% CI       V5 P-value
                       <char>    <num>     <num>   <num>    <num>   <num>
 1:             Simple median -0.02900   0.02500 -0.0790  2.1e-02  0.2500
 2:           Weighted median  0.00038   0.02800 -0.0540  5.5e-02  0.9900
 3: Penalized weighted median -0.02800   0.02800 -0.0830  2.6e-02  0.3100
 4:                       IVW  0.01100   0.02800 -0.0440  6.6e-02  0.6900
 5:             Penalized IVW -0.04900   0.01700 -0.0820 -1.6e-02  0.0035
 6:                Robust IVW -0.03800   0.02300 -0.0830  6.6e-03  0.0950
 7:      Penalized robust IVW -0.04900   0.01800 -0.0850 -1.4e-02  0.0062
 8:                  MR-Egger  0.11000   0.05700 -0.0060  2.2e-01  0.0640
 9:               (intercept) -0.00260   0.00130 -0.0052  7.8e-05  0.0570
10:        Penalized MR-Egger  0.05000   0.03400 -0.0160  1.2e-01  0.1400
11:               (intercept) -0.00230   0.00079 -0.0039 -7.7e-04  0.0034
12:           Robust MR-Egger  0.03300   0.04500 -0.0550  1.2e-01  0.4600
13:               (intercept) -0.00190   0.00098 -0.0038  4.7e-05  0.0560
14: Penalized robust MR-Egger  0.04400   0.03700 -0.0280  1.2e-01  0.2400
15:               (intercept) -0.00220   0.00083 -0.0039 -6.1e-04  0.0071
#+end_quote

******* IgG

#+begin_quote
r$> igg
                       Method Estimate Std Error  95% CI     V5 P-value
                       <char>    <num>     <num>   <num>  <num>   <num>
 1:             Simple median  3.5e-02   0.02400 -0.0110 0.0820   0.140
 2:           Weighted median  3.6e-02   0.02600 -0.0160 0.0870   0.170
 3: Penalized weighted median  3.6e-02   0.02600 -0.0150 0.0880   0.170
 4:                       IVW  3.2e-02   0.01800 -0.0024 0.0660   0.069
 5:             Penalized IVW  3.4e-02   0.01500  0.0038 0.0650   0.027
 6:                Robust IVW  3.6e-02   0.01700  0.0028 0.0700   0.034
 7:      Penalized robust IVW  3.7e-02   0.01600  0.0059 0.0690   0.020
 8:                  MR-Egger  2.9e-02   0.03600 -0.0410 0.0990   0.420
 9:               (intercept)  8.5e-05   0.00085 -0.0016 0.0017   0.920
10:        Penalized MR-Egger  3.7e-02   0.03100 -0.0240 0.0990   0.240
11:               (intercept) -9.3e-05   0.00074 -0.0016 0.0014   0.900
12:           Robust MR-Egger  4.0e-02   0.03200 -0.0220 0.1000   0.210
13:               (intercept) -9.2e-05   0.00073 -0.0015 0.0013   0.900
14: Penalized robust MR-Egger  4.4e-02   0.03000 -0.0140 0.1000   0.140
15:               (intercept) -1.9e-04   0.00069 -0.0015 0.0012   0.790
#+end_quote


*** Notes on reading

#+begin_ai
I know about Mendelian randomisation, but what is the 'MR-Egger' method?

[AI]: MRâEgger is an extension of the standard Mendelian randomisation (MR) framework that helps detect and adjust for a common problem known as directional (or unbalanced) pleiotropy. Hereâs what that means and how MRâEgger works:

1. Background in MR:  
   In MR studies, genetic variants (usually single nucleotide polymorphisms, or SNPs) are used as instrumental variables (IVs) to estimate the causal effect of an exposure on an outcome. A key assumption here is that these genetic instruments affect the outcome only through the exposure, not through any other pathway. When a genetic variant influences the outcome via additional pathways, itâs said to exhibit "pleiotropy."

2. The Challenge of Pleiotropy:  
   Pleiotropy becomes particularly problematic when it is directionalâmeaning the pleiotropic effects are not balanced around zero but tend to push the outcome in one direction. This violates one of the core assumptions of a valid IV, potentially biasing the causal estimate.

3. What MRâEgger Does:  
   MRâEgger regression adapts the idea of Egger regression (originally developed to detect publication bias in meta-analyses) to MR:
   - It involves regressing the SNPâoutcome association estimates against the SNPâexposure association estimates.
   - Unlike the traditional inverse-variance weighted (IVW) MR method (which assumes the intercept is zero), MRâEgger allows the intercept to be non-zero.
   - This intercept represents the average pleiotropic effect across the genetic instruments. If it is significantly different from zero, that suggests the presence of directional pleiotropy.

4. How to Interpret the MRâEgger Output:  
   - The Slope: It represents the causal effect of the exposure on the outcome, adjusted for the pleiotropic effects.
   - The Intercept: A statistically significant intercept is an indication that the IVs collectively are affecting the outcome via pathways independent of the exposure. In other words, it signals directional pleiotropy.

5. Assumptions and Limitations:  
   - MRâEgger relies on the Instrument Strength Independent of Direct Effect (InSIDE) assumption. This means that the magnitude of the pleiotropic effects should be independent of the strength of the SNPâexposure association.
   - While MRâEgger can provide a more robust estimate in the presence of pleiotropy, it often comes at the cost of decreased precision (i.e., a wider confidence interval) compared to standard methods.
   - It is best seen as a sensitivity analysis tool, used alongside other methods to gauge the robustness of the findings.

In summary, MRâEgger regression is a useful tool in the MR toolkit. It helps to test for and adjust the causal estimates for the influence of directional pleiotropy, thereby enhancing the reliability of MR inferences when the standard IV assumptions might be violated.

[ME]: 
#+end_ai

** DONE Bias in sign of lead SNPs for IgA

Found this while doing MR, e.g. for IgA:
#+begin_src
> dat[, .N, by = sign(beta)]
    sign     N
   <num> <int>
1:    -1    61
2:     1    44
#+end_src

IgM:
#+begin_src
> dat[, .N, by = sign(beta)]
    sign     N
   <num> <int>
1:     1    42
2:    -1    46
#+end_src

IgG:
#+begin_src
> dat[, .N, by = sign(beta)]
    sign     N
   <num> <int>
1:    -1    11
2:     1     7
#+end_src

For IgA, there are 19 SNPs with beta < -0.5 and 16 of these are on chromosome 1. These do look quite close, all between 19.4Mb and 31Mb. They may just be one continuous signal.

Turns out there is just one big signal on chromosome 1. I will need to reconsider clumping.
** DONE Reconsidering the clumping approach <2025-03-12 Wed>

Problem is the RUNX3 signal in IgA, GWS SNPs spanning the interval 19.5-31Mb and beyond.

How can we do it? Can use =distance_clump= as a checkpoint then generate plots with 1Mb either side.

Logging the candidate lead SNPs to drop in =config.yaml=

*** IgA
**** Chromosome 1
#+begin_quote
            rsid chromosome base_pair_location       p_value
          <char>      <int>              <int>         <num>
 1:  rs746234782          1           19432479  6.140871e-09
 2:  rs543261951          1           20344243  3.259902e-11
 3:  rs762141322          1           21376594  8.899024e-12
 4:  rs535269494          1           21998347  5.539661e-16
 5:  rs765348868          1           22971602  4.219736e-11
 6:  rs781445232          1           23501623  5.569659e-17
 7:  rs546722789          1           24306004  6.446018e-33
 8:  rs188468174          1           24965206 1.668808e-308
 9:   rs74593753          1           25499340  3.107399e-63
10:  rs760351385          1           26014185  9.730406e-24
11:  rs765183915          1           26699947  8.382099e-23
12:  rs200807314          1           27595000  3.801186e-21
13:   rs11582631          1           28731992  2.360482e-19
14:  rs755241705          1           29303382  1.050294e-17
15:  rs762472871          1           30028204  6.390226e-15
16: rs1053363817          1           30966900  2.179885e-10
17:    rs7544568          1           38173536  2.282975e-10
18:   rs11204701          1          150689703  1.110827e-08
19:   rs79316700          1          161595524  3.264760e-10
20:    rs3766151          1          169886435  1.741997e-11
21:    rs4090390          1          173177782  1.266369e-15
22:   rs10920074          1          200943599  2.730469e-25
23:   rs73100295          1          217389764  3.848169e-08
#+end_quote

You can even see the signal decaying in the p-values here. Was silly to identify this as distinct hits.

rs188468174 and rs7544568

On chromosome 4, two SNPs [[https://ldlink.nih.gov/?var1=rs2101521&var2=rs10517538&pop=CEU%2BTSI%2BFIN%2BGBR%2BIBS&genome_build=grch38_high_coverage&r2_d=r2&tab=ldpop][are within 1.5Mb but are not in LD]]

On chromosome 5, [[https://ldlink.nih.gov/?var1=rs28744551&var2=rs6859219&pop=CEU%2BTSI%2BFIN%2BGBR%2BIBS&genome_build=grch38_high_coverage&r2_d=r2&tab=ldpop][same story again]]

*** IgG

Just dropped a handful here.

*** IgM

**** To drop

- rs12061333 (chr1)
- rs34635213 (chr2)
- rs2336142 (chr3)
- rs2395833 (chr7)
- rs118008550 (chr14)

['rs12061333', 'rs34635213', 'rs2336142', 'rs2395833', 'rs118008550']

**** TODO chr1

Not sure about rs12040769 and rs188468174, they look to be separate but they're still close, I want to check the [[https://ldlink.nih.gov/?var1=rs12040769&var2=rs188468174&pop=CEU%2BTSI%2BFIN%2BGBR%2BIBS&genome_build=grch38_high_coverage&r2_d=r2&tab=ldpop][LD]]. Ok, they're not in LD.

**** chr4

See rs865020 plot: close but all three seem independent.

#+begin_src
         rsid chromosome base_pair_location      p_value
       <char>      <int>              <int>        <num>
1:  rs1397934          4           40185976 3.077926e-15
2: rs67960624          4           67613670 3.188564e-09
3: rs17611664          4           99837400 1.234269e-09
4:   rs865020          4          101398129 7.050093e-13
5:  rs1080081          4          103029268 1.759724e-11
#+end_src

[[https://ldlink.nih.gov/?var1=rs17611664&var2=rsrs865020&pop=CEU%2BTSI%2BFIN%2BGBR%2BIBS&genome_build=grch38_high_coverage&r2_d=r2&tab=ldpop][rs17611664 and rs865020 are not in LD]] and [[https://ldlink.nih.gov/?var1=rs1080081&var2=rs865020&pop=CEU%2BTSI%2BFIN%2BGBR%2BIBS&genome_build=grch38_high_coverage&r2_d=r2&tab=ldpop][rs865020 and rs1080081]] are not either.

**** chr9

[[https://ldlink.nih.gov/?var1=rs140275930&var2=rs12554596&pop=CEU%2BTSI%2BFIN%2BGBR%2BIBS&genome_build=grch38_high_coverage&r2_d=r2&tab=ldpop][rs140275930 and rs12554596 are not in LD]]

*** Lymphocyte counts

I collapsed variants by hand by inspecting locuszoomr plots, checking the r2 for variants close to one another, and removing the less significant. Can I automate this?

**** The script

#+begin_ai
I have a data.table object containing SNPs. I want to look at pairs of SNPs which lie within a specified minimum distance of one another on the same chromosome. Are there any features of data.table that will allow me to do this efficiently?

[AI]: Yes â you can do this very efficiently with data.tableâs nonâequi joins (and, if you prefer, rolling joins or foverlaps). The idea is to âself joinâ your SNP table by matching records on the same chromosome and then enforcing a condition on the positions (e.g., that the distance is less than your minimum threshold). Because data.table maintains the keys in a sorted order and uses binary search for joins, these non-equi joins can be extremely fast even for large datasets.

For example, suppose your data.table (called DT) has columns "chr" (chromosome) and "pos" (position). You can do something like the following (assuming you want to find pairs where SNP2 is within min_dist of SNP1):

ââlibrary(data.table)

ââ# Example data
ââDT <- data.table(chr = c("chr1", "chr1", "chr1", "chr2","chr2"),
ââââââââââpos = c(100, 110, 130, 50, 55))
ââmin_dist <- 20

ââ# Set keys for efficient join
ââsetkey(DT, chr, pos)

ââ# Self join using non-equi conditions:
ââpairs <- DT[DT, 
ââââallow.cartesian = TRUE,
ââââon = .(chr, pos >= pos, pos <= pos + min_dist), 
âââânomatch = 0]

In this join, the i. columns refer to the "outer" DT, and the "x" columns refer to the matched SNPs. This code finds, for each SNP (from the i-side), all SNPs on the same chromosome that are located between its position and position + min_dist. (You might want to adjust the join direction or filter out self-matches as needed.)

If you need to consider SNPs within a window on either side of a given SNP (both upstream and downstream), you could modify the join conditions accordingly or use a combination of two joins.

Another approach (especially if you want to work with intervals) is to use foverlaps. In that case you would treat each SNP as an interval â for example, setting the start and end positions as pos and pos + min_dist â and then perform an overlap join to find SNP pairs that fall into each otherâs windows.

Either way, data.tableâs non-equi join syntax provides a very concise and efficient way to do what you need.

So in summary, data.table supports exactly the operation you need and doing self joins with non-equi conditions is the recommended approach for efficiently finding pairs of SNPs within a specified distance on the same chromosome.

[ME]: 
#+end_ai

So the non-equi join in data.table is given by:
#+begin_src
res <- dat[dat, allow.cartesian = TRUE, on = .(chromosome, pos >= pos_lower, pos <= pos_upper), nomatch = 0]
res <- res[rsid != i.rsid]
#+end_src

*** Ideas for an automated solution

What if I use ldetect to get approximate LD blocks?

Rely on some kind of classifier?

Smoothing approach that can model decay of signal?

#+begin_ai
Are you listening?

[AI]: Yes, I'm listening. How can I help you today?

[ME]: I want to clump GWAS summary statistics to identify discrete signals, but I have no LD information available, only the summary statistics. I don't have the genotype data either. I'm thinking about developing a solution based on the 'decay' of the p-values away from the centre of the signals. Maybe some form of smoothing? Or is there a better classifier?

[AI]: You're on the right track thinking about the âdecayâ of association signals as a possible clue for separating true loci from nearby noise, but there are several challenges and alternative strategies to consider.

1. LD versus physical distance:  
ââ¢ In typical clumping approaches, you use linkage disequilibrium (LD) from genotype data (or a reference panel) to decide whether two nearby associations are âindependentâ versus simply correlated by LD.  
ââ¢ Physical distance (or a decay in p-values away from a lead SNP) is only an approximate surrogate for LD. In many regions, LD decays roughly with distance, but this relationship is not uniform genomeâwide. Some regions have extended LD (e.g., the MHC), while others break down faster. So, a decay/smoothing approach might work well in some regions but could misclassify signals in others.

2. Smoothing or peak detection methods:  
ââ¢ You could consider applying a smoothing algorithm (for example, Gaussian kernel smoothing or local regression) to your âlog(p) values across the genome. This might help highlight peaks and allow you to define a âsignal centreâ from which you can observe decay.  
ââ¢ Once smoothed, you could use peak detection or changeâpoint analysis to detect boundariesâessentially segments of the genome that âbelongâ to a single signal. However, choosing the window size and kernel parameters will require careful calibration.  
ââ¢ Simulations can help here: simulate summary statistics with known âsignalsâ and noise to assess how well your smoothing/peak detection method recovers the underlying clumps.

3. Alternative approaches without direct LD information:  
ââ¢ Even if you don't have your own genotype data, publicly available resources (e.g., 1000 Genomes or the Haplotype Reference Consortium) can sometimes serve as a proxy for LD. Although these wonât match your sample perfectly, they could give you an approximate LD structure that might improve clumping.  
ââ¢ There are summaryâstatistic fineâmapping tools (such as COJO from GCTA, FINEMAP, or SuSiE) that usually require an LD reference. In many cases, using an LD referenceâeven an imperfect oneâtends to perform better than ignoring LD altogether.
ââ¢ Alternatively, you might consider spatial statistical approaches like hidden Markov models (HMMs) or changeâpoint detection methods that incorporate the idea that the association signal âdecaysâ or changes as you move away from a causal variant. A Bayesian hierarchical model could also incorporate both the âstrengthâ and âspreadâ of significance across genomic locations.

4. Considerations and potential pitfalls:  
ââ¢ P-value âdecayâ might be confounded by local genomic features (e.g., gene density, recombination rates, or differential imputation quality) that affect both association statistics and the physical extent of signals.  
ââ¢ Relying solely on a smoothed decay curve might miss complex signal patterns (like multiple independent causal variants in tight proximity) or may merge signals that are actually distinct.
ââ¢ Calibration is crucial. Youâll likely need extensive simulation and cross-validation using loci where independent LD-based clumping is available for comparison.

In summary, while smoothing the p-value signal is a creative idea, consider it as one component of your analysis rather than a complete replacement for LD-based clumping. If obtaining a reference LD panel is infeasible, you might combine smoothing/peak detection with methods that account for spatial variation, or explore approximate LD estimates from public data. This multi-pronged strategy will likely yield better identification of discrete signals from your summary statistics.

What do you think about these directions? Do you need more details on any particular method or simulation strategy?

[ME]: 
#+end_ai
